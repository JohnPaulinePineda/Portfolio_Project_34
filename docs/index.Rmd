---
title: "Supervised Learning : Exploring Penalized Models for Handling High-Dimensional Survival Data"
author: "John Pauline Pineda"
date: "June 28, 2023"
output: 
  html_document:
    toc: true
    toc_depth: 3
    theme: readable
    highlight: tango
    css: doc.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.width=15, fig.height=10)
```
# **1. Table of Contents**
|
| This project explores different regularization methods for minimizing model complexity by promoting coefficient sparsity in high-dimensional survival data using various helpful packages in <mark style="background-color: #CCECFF">**R**</mark>. Using a Cox Proportional Hazards Regression model structure, penalty functions applied during coefficient estimation included the **Least Absolute Shrinkage and Selection Operator**, **Elastic Net**, **Minimax Concave Penalty**, **Smoothly Clipped Absolute Deviation** and **Fused Least Absolute Shrinkage and Selection Operator**. The predictive performance for each algorithm was evaluated using the time-dependent area under the receiver operating characteristic curve (AUROC) metric through both internal bootstrap and external validation methods. Model calibration was similarly assessed by plotting the predicted probabilities from the model versus the actual survival probabilities. The differences in survival time for different risk groups determined from the calibration analyses were additionally examined using the Kaplan-Meier survival curves.
|
| Penalized regression is a form of variable selection method aimed at reducing model complexity by seeking a smaller subset of informative variables. This process keeps all the predictor variables in the model but constrains (regularizes) the regression coefficients by shrinking them toward zero, in addition to setting some coefficients exactly equal to zero, and is directly built as extensions of standard regression coefficient estimation by incorporating a penalty in the loss function. The algorithms applied in this study (mostly contained in the <mark style="background-color: #CCECFF">**hdnom**</mark>, <mark style="background-color: #CCECFF">**ncvreg**</mark>, <mark style="background-color: #CCECFF">**survival**</mark>, <mark style="background-color: #CCECFF">**glmnet**</mark> and <mark style="background-color: #CCECFF">**penalized**</mark>packages) attempt to evaluate various penalties for over-confidence in the parameter estimates and accept a slightly worse fit in order to have a more parsimonious model.
|
##  1.1 Sample Data
|
| The <mark style="background-color: #EEEEEE;color: #FF0000">**peakVO2**</mark>  dataset from the  <mark style="background-color: #CCECFF">**randomForestSRC**</mark> package was used for this illustrated example.
|
| Preliminary dataset assessment:
|
| **[A]** 2231 rows (observations)
| 
| **[B]** 41 columns (variables)
|      **[B.1]** 1/41 survival event status = <span style="color: #FF0000">died</span> variable (factor)
|             **[B.1.1]** Event = <span style="color: #FF0000">died=1</span> 
|             **[B.1.2]** Censored or Non-Event = <span style="color: #FF0000">died=0</span>
|      **[B.2]** 1/41 survival time = <span style="color: #FF0000">ttodead</span> variable (numeric)
|      **[B.3]** 39/41 predictors = All remaining variables (26/39 factor + 13/39 numeric)

|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.1, warning=FALSE, message=FALSE}
##################################
# Loading R libraries
##################################
library(survival)
library(survminer)
library(mice)
library(foreign)
library(rms)
library(Hmisc)
library(VIM)
library(gridExtra)
library(finalfit)
library(knitr)
library(dplyr)
library(gtsummary)
library(tidyr)
library(purrr)
library(moments)
library(skimr)
library(caret)
library(corrplot)
library(randomForestSRC)
library(SurvMetrics)
library(pec)
library(hdnom)
library(ncvreg)
library(glmnet)
library(penalized)

##################################
# Loading source and
# formulating the train set
##################################
data(peakVO2)
peakVO2 <- as.data.frame(peakVO2)

##################################
# Converting survival time
# to discrete monthly data
##################################
peakVO2$ttodead <- ceiling(peakVO2$ttodead*12)
peakVO2.Source <- peakVO2

##################################
# Setting the appropriate data types
# for exploratory data analysis
##################################
peakVO2.Assessment <- (as.data.frame(sapply(peakVO2, function(x) max(x))))
names(peakVO2.Assessment) <- c("Max.Value")
peakVO2.Assessment$Variables <- rownames(peakVO2.Assessment)
peakVO2.Assessment

(peakVO2.FactorNames <- peakVO2.Assessment[peakVO2.Assessment[,1]==1,2])
peakVO2.Factor <- peakVO2[,peakVO2.FactorNames]
peakVO2.Factor <- as.data.frame(lapply(peakVO2.Factor, factor))

peakVO2.Numeric <- as.data.frame(peakVO2[,!names(peakVO2) %in% peakVO2.FactorNames])

peakVO2 <- data.frame(peakVO2.Numeric,peakVO2.Factor)

##################################
# Performing a general exploration of the data set
##################################
dim(peakVO2)
str(peakVO2)
summary(peakVO2)

##################################
# Formulating a data type assessment summary
##################################
PDA <- peakVO2
(PDA.Summary <- data.frame(
  Column.Index=c(1:length(names(PDA))),
  Column.Name= names(PDA), 
  Column.Type=sapply(PDA, function(x) class(x)), 
  row.names=NULL)
)

```

</details>

##  1.2 Data Quality Assessment
|
| Data quality assessment:
|
| **[A]** No missing observations noted for any variable.
|
| **[B]** Low variance observed for 10 variables with First.Second.Mode.Ratio>5.
|      **[B.1]** <span style="color: #FF0000">dilver</span> variable (factor)
|      **[B.2]** <span style="color: #FF0000">nifed</span> variable (factor)
|      **[B.3]** <span style="color: #FF0000">angioten.II</span> variable (factor)
|      **[B.4]** <span style="color: #FF0000">vasodilator</span> variable (factor)
|      **[B.5]** <span style="color: #FF0000">diuretic.loop</span> variable (factor)
|      **[B.6]** <span style="color: #FF0000">diuretic.thiazide</span> variable (factor)
|      **[B.7]** <span style="color: #FF0000">insulin</span> variable (factor)
|      **[B.8]** <span style="color: #FF0000">q.wave.mi</span> variable (factor)
|      **[B.9]** <span style="color: #FF0000">niddm</span> variable (factor)
|      **[B.10]** <span style="color: #FF0000">black</span> variable (factor)
|
| **[C]** No low variance observed for any variable with Unique.Count.Ratio<0.01.
|
| **[D]** No high skewness observed for any variable with Skewness>3 or Skewness<(-3).
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.2, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DQA <- peakVO2

##################################
# Formulating an overall data quality assessment summary
##################################
(DQA.Summary <- data.frame(
  Column.Index=c(1:length(names(DQA))),
  Column.Name= names(DQA),
  Column.Type=sapply(DQA, function(x) class(x)),
  Row.Count=sapply(DQA, function(x) nrow(DQA)),
  NA.Count=sapply(DQA,function(x)sum(is.na(x))),
  Fill.Rate=sapply(DQA,function(x)format(round((sum(!is.na(x))/nrow(DQA)),3),nsmall=3)),
  row.names=NULL)
)

##################################
# Listing all descriptors
##################################
DQA.Descriptors <- DQA

##################################
# Listing all numeric Descriptors
##################################
DQA.Descriptors.Numeric <- DQA.Descriptors[,sapply(DQA.Descriptors, is.numeric)]

if (length(names(DQA.Descriptors.Numeric))>0) {
    print(paste0("There are ",
               (length(names(DQA.Descriptors.Numeric))),
               " numeric descriptor variable(s)."))
} else {
  print("There are no numeric descriptor variables.")
}

##################################
# Listing all factor Descriptors
##################################
DQA.Descriptors.Factor <- DQA.Descriptors[,sapply(DQA.Descriptors, is.factor)]

if (length(names(DQA.Descriptors.Factor))>0) {
    print(paste0("There are ",
               (length(names(DQA.Descriptors.Factor))),
               " factor descriptor variable(s)."))
} else {
  print("There are no factor descriptor variables.")
}

##################################
# Formulating a data quality assessment summary for factor Descriptors
##################################
if (length(names(DQA.Descriptors.Factor))>0) {

  ##################################
  # Formulating a function to determine the first mode
  ##################################
  FirstModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    ux[tab == max(tab)]
  }

  ##################################
  # Formulating a function to determine the second mode
  ##################################
  SecondModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    fm = ux[tab == max(tab)]
    sm = x[!(x %in% fm)]
    usm <- unique(sm)
    tabsm <- tabulate(match(sm, usm))
    ifelse(is.na(usm[tabsm == max(tabsm)])==TRUE,
           return("x"),
           return(usm[tabsm == max(tabsm)]))
  }

  (DQA.Descriptors.Factor.Summary <- data.frame(
  Column.Name= names(DQA.Descriptors.Factor),
  Column.Type=sapply(DQA.Descriptors.Factor, function(x) class(x)),
  Unique.Count=sapply(DQA.Descriptors.Factor, function(x) length(unique(x))),
  First.Mode.Value=sapply(DQA.Descriptors.Factor, function(x) as.character(FirstModes(x)[1])),
  Second.Mode.Value=sapply(DQA.Descriptors.Factor, function(x) as.character(SecondModes(x)[1])),
  First.Mode.Count=sapply(DQA.Descriptors.Factor, function(x) sum(na.omit(x) == FirstModes(x)[1])),
  Second.Mode.Count=sapply(DQA.Descriptors.Factor, function(x) sum(na.omit(x) == SecondModes(x)[1])),
  Unique.Count.Ratio=sapply(DQA.Descriptors.Factor, function(x) format(round((length(unique(x))/nrow(DQA.Descriptors.Factor)),3), nsmall=3)),
  First.Second.Mode.Ratio=sapply(DQA.Descriptors.Factor, function(x) format(round((sum(na.omit(x) == FirstModes(x)[1])/sum(na.omit(x) == SecondModes(x)[1])),3), nsmall=3)),
  row.names=NULL)
  )

}

##################################
# Formulating a data quality assessment summary for numeric Descriptors
##################################
if (length(names(DQA.Descriptors.Numeric))>0) {

  ##################################
  # Formulating a function to determine the first mode
  ##################################
  FirstModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    ux[tab == max(tab)]
  }

  ##################################
  # Formulating a function to determine the second mode
  ##################################
  SecondModes <- function(x) {
    ux <- unique(na.omit(x))
    tab <- tabulate(match(x, ux))
    fm = ux[tab == max(tab)]
    sm = na.omit(x)[!(na.omit(x) %in% fm)]
    usm <- unique(sm)
    tabsm <- tabulate(match(sm, usm))
    ifelse(is.na(usm[tabsm == max(tabsm)])==TRUE,
           return(0.00001),
           return(usm[tabsm == max(tabsm)]))
  }

  (DQA.Descriptors.Numeric.Summary <- data.frame(
  Column.Name= names(DQA.Descriptors.Numeric),
  Column.Type=sapply(DQA.Descriptors.Numeric, function(x) class(x)),
  Unique.Count=sapply(DQA.Descriptors.Numeric, function(x) length(unique(x))),
  Unique.Count.Ratio=sapply(DQA.Descriptors.Numeric, function(x) format(round((length(unique(x))/nrow(DQA.Descriptors.Numeric)),3), nsmall=3)),
  First.Mode.Value=sapply(DQA.Descriptors.Numeric, function(x) format(round((FirstModes(x)[1]),3),nsmall=3)),
  Second.Mode.Value=sapply(DQA.Descriptors.Numeric, function(x) format(round((SecondModes(x)[1]),3),nsmall=3)),
  First.Mode.Count=sapply(DQA.Descriptors.Numeric, function(x) sum(na.omit(x) == FirstModes(x)[1])),
  Second.Mode.Count=sapply(DQA.Descriptors.Numeric, function(x) sum(na.omit(x) == SecondModes(x)[1])),
  First.Second.Mode.Ratio=sapply(DQA.Descriptors.Numeric, function(x) format(round((sum(na.omit(x) == FirstModes(x)[1])/sum(na.omit(x) == SecondModes(x)[1])),3), nsmall=3)),
  Minimum=sapply(DQA.Descriptors.Numeric, function(x) format(round(min(x,na.rm = TRUE),3), nsmall=3)),
  Mean=sapply(DQA.Descriptors.Numeric, function(x) format(round(mean(x,na.rm = TRUE),3), nsmall=3)),
  Median=sapply(DQA.Descriptors.Numeric, function(x) format(round(median(x,na.rm = TRUE),3), nsmall=3)),
  Maximum=sapply(DQA.Descriptors.Numeric, function(x) format(round(max(x,na.rm = TRUE),3), nsmall=3)),
  Skewness=sapply(DQA.Descriptors.Numeric, function(x) format(round(skewness(x,na.rm = TRUE),3), nsmall=3)),
  Kurtosis=sapply(DQA.Descriptors.Numeric, function(x) format(round(kurtosis(x,na.rm = TRUE),3), nsmall=3)),
  Percentile25th=sapply(DQA.Descriptors.Numeric, function(x) format(round(quantile(x,probs=0.25,na.rm = TRUE),3), nsmall=3)),
  Percentile75th=sapply(DQA.Descriptors.Numeric, function(x) format(round(quantile(x,probs=0.75,na.rm = TRUE),3), nsmall=3)),
  row.names=NULL)
  )

}

##################################
# Identifying potential data quality issues
##################################

##################################
# Checking for missing observations
##################################
if ((nrow(DQA.Summary[DQA.Summary$NA.Count>0,]))>0){
  print(paste0("Missing observations noted for ",
               (nrow(DQA.Summary[DQA.Summary$NA.Count>0,])),
               " variable(s) with NA.Count>0 and Fill.Rate<1.0."))
  DQA.Summary[DQA.Summary$NA.Count>0,]
} else {
  print("No missing observations noted.")
}

##################################
# Checking for zero or near-zero variance Descriptors
##################################
if (length(names(DQA.Descriptors.Factor))==0) {
  print("No factor descriptors noted.")
} else if (nrow(DQA.Descriptors.Factor.Summary[as.numeric(as.character(DQA.Descriptors.Factor.Summary$First.Second.Mode.Ratio))>5,])>0){
  print(paste0("Low variance observed for ",
               (nrow(DQA.Descriptors.Factor.Summary[as.numeric(as.character(DQA.Descriptors.Factor.Summary$First.Second.Mode.Ratio))>5,])),
               " factor variable(s) with First.Second.Mode.Ratio>5."))
  DQA.Descriptors.Factor.Summary[as.numeric(as.character(DQA.Descriptors.Factor.Summary$First.Second.Mode.Ratio))>5,]
} else {
  print("No low variance factor descriptors due to high first-second mode ratio noted.")
}

if (length(names(DQA.Descriptors.Numeric))==0) {
  print("No numeric descriptors noted.")
} else if (nrow(DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$First.Second.Mode.Ratio))>5,])>0){
  print(paste0("Low variance observed for ",
               (nrow(DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$First.Second.Mode.Ratio))>5,])),
               " numeric variable(s) with First.Second.Mode.Ratio>5."))
  DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$First.Second.Mode.Ratio))>5,]
} else {
  print("No low variance numeric descriptors due to high first-second mode ratio noted.")
}

if (length(names(DQA.Descriptors.Numeric))==0) {
  print("No numeric descriptors noted.")
} else if (nrow(DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Unique.Count.Ratio))<0.01,])>0){
  print(paste0("Low variance observed for ",
               (nrow(DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Unique.Count.Ratio))<0.01,])),
               " numeric variable(s) with Unique.Count.Ratio<0.01."))
  DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Unique.Count.Ratio))<0.01,]
} else {
  print("No low variance numeric descriptors due to low unique count ratio noted.")
}

##################################
# Checking for skewed Descriptors
##################################
if (length(names(DQA.Descriptors.Numeric))==0) {
  print("No numeric descriptors noted.")
} else if (nrow(DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Skewness))>3 |
                                               as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Skewness))<(-3),])>0){
  print(paste0("High skewness observed for ",
  (nrow(DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Skewness))>3 |
                                               as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Skewness))<(-3),])),
  " numeric variable(s) with Skewness>3 or Skewness<(-3)."))
  DQA.Descriptors.Numeric.Summary[as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Skewness))>3 |
                                 as.numeric(as.character(DQA.Descriptors.Numeric.Summary$Skewness))<(-3),]
} else {
  print("No skewed numeric descriptors noted.")
}

```

</details>

##  1.3 Data Preprocessing

###  1.3.1 Outlier
|
| Outlier data assessment:
|
| **[A]** Outliers noted for 12 variables  with the numeric data visualized through a boxplot including observations classified as suspected outliers using the IQR criterion. The IQR criterion means that all observations above the (75th percentile + 1.5 x IQR) or below the (25th percentile - 1.5 x IQR) are suspected outliers, where IQR is the difference between the third quartile (75th percentile) and first quartile (25th percentile). Outlier treatment for numerical stability remains optional depending on potential model requirements for the subsequent steps.
|      **[A.1]** <span style="color: #FF0000">age</span> variable (33 outliers detected)
|      **[A.2]** <span style="color: #FF0000">resting.systolic.bp</span> variable (26 outliers detected)
|      **[A.3]** <span style="color: #FF0000">resting.hr</span> variable (9 outliers detected)
|      **[A.4]** <span style="color: #FF0000">bmi</span> variable (34 outliers detected)
|      **[A.5]** <span style="color: #FF0000">peak.rer</span> variable (102 outliers detected)
|      **[A.6]** <span style="color: #FF0000">peak.vo2</span> variable (40 outliers detected)
|      **[A.7]** <span style="color: #FF0000">interval</span> variable (25 outliers detected)
|      **[A.8]** <span style="color: #FF0000">bun</span> variable (116 outliers detected)
|      **[A.9]** <span style="color: #FF0000">sodium</span> variable (140 outliers detected)
|      **[A.10]** <span style="color: #FF0000">hgb</span> variable (83 outliers detected)
|      **[A.11]** <span style="color: #FF0000">glucose</span> variable (222 outliers detected)
|      **[A.12]** <span style="color: #FF0000">crcl</span> variable (82 outliers detected)
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.1, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DPA <- peakVO2

##################################
# Listing all predictors
##################################
DPA.Predictors <- DPA[,!names(DPA) %in% c("died","ttodead")]

##################################
# Listing all numeric predictors
##################################
DPA.Predictors.Numeric <- DPA.Predictors[,sapply(DPA.Predictors, is.numeric)]

##################################
# Identifying outliers for the numeric predictors
##################################
OutlierCountList <- c()

for (i in 1:ncol(DPA.Predictors.Numeric)) {
  Outliers <- boxplot.stats(DPA.Predictors.Numeric[,i])$out
  OutlierCount <- length(Outliers)
  OutlierCountList <- append(OutlierCountList,OutlierCount)
  OutlierIndices <- which(DPA.Predictors.Numeric[,i] %in% c(Outliers))
  boxplot(DPA.Predictors.Numeric[,i], 
          ylab = names(DPA.Predictors.Numeric)[i], 
          main = names(DPA.Predictors.Numeric)[i],
          horizontal=TRUE)
  mtext(paste0(OutlierCount, " Outlier(s) Detected"))
}

OutlierCountSummary <- as.data.frame(cbind(names(DPA.Predictors.Numeric),(OutlierCountList)))
names(OutlierCountSummary) <- c("NumericPredictors","OutlierCount")
OutlierCountSummary$OutlierCount <- as.numeric(as.character(OutlierCountSummary$OutlierCount))
NumericPredictorWithOutlierCount <- nrow(OutlierCountSummary[OutlierCountSummary$OutlierCount>0,])
print(paste0(NumericPredictorWithOutlierCount, " numeric variable(s) were noted with outlier(s)." ))

##################################
# Gathering descriptive statistics
##################################
(DPA_Skimmed <- skim(DPA.Predictors.Numeric))

###################################
# Verifying the data dimensions
###################################
dim(DPA.Predictors.Numeric)

```

</details>

###  1.3.2 Zero and Near-Zero Variance
|
| Zero and near-zero variance data assessment:
|
| **[A]** Low variance noted for 10 variables from the previous data quality assessment using a lower threshold.
|
| **[B]** Low variance noted for 2 variables using a preprocessing summary from the <mark style="background-color: #CCECFF">**caret**</mark> package. The <span style="color: #0000FF">nearZeroVar</span> method using both the <span style="color: #0000FF">freqCut</span> and <span style="color: #0000FF">uniqueCut</span> criteria set at 95/5 and 10, respectively, were applied on the dataset.
|      **[B.1]** <span style="color: #FF0000">dilver</span> variable (factor)
|      **[B.2]** <span style="color: #FF0000">nifed</span> variable (factor)
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.2, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DPA <- peakVO2

##################################
# Gathering descriptive statistics
##################################
(DPA_Skimmed <- skim(DPA))

##################################
# Identifying columns with low variance
###################################
DPA_LowVariance <- nearZeroVar(DPA,
                               freqCut = 95/5,
                               uniqueCut = 10,
                               saveMetrics= TRUE)
(DPA_LowVariance[DPA_LowVariance$nzv,])

if ((nrow(DPA_LowVariance[DPA_LowVariance$nzv,]))==0){
  
  print("No low variance predictors noted.")
  
} else {

  print(paste0("Low variance observed for ",
               (nrow(DPA_LowVariance[DPA_LowVariance$nzv,])),
               " numeric variable(s) with First.Second.Mode.Ratio>4 and Unique.Count.Ratio<0.10."))
  
  DPA_LowVarianceForRemoval <- (nrow(DPA_LowVariance[DPA_LowVariance$nzv,]))
  
  print(paste0("Low variance can be resolved by removing ",
               (nrow(DPA_LowVariance[DPA_LowVariance$nzv,])),
               " numeric variable(s)."))
  
  for (j in 1:DPA_LowVarianceForRemoval) {
  DPA_LowVarianceRemovedVariable <- rownames(DPA_LowVariance[DPA_LowVariance$nzv,])[j]
  print(paste0("Variable ",
               j,
               " for removal: ",
               DPA_LowVarianceRemovedVariable))
  }
  
  DPA %>%
  skim() %>%
  dplyr::filter(skim_variable %in% rownames(DPA_LowVariance[DPA_LowVariance$nzv,]))

  ##################################
  # Filtering out columns with low variance
  #################################
  DPA_ExcludedLowVariance <- DPA[,!names(DPA) %in% rownames(DPA_LowVariance[DPA_LowVariance$nzv,])]
  
  ##################################
  # Gathering descriptive statistics
  ##################################
  (DPA_ExcludedLowVariance_Skimmed <- skim(DPA_ExcludedLowVariance))
}

```

</details>

###  1.3.3 Collinearity
|
| High collinearity data assessment:
|
| **[A]** No high correlation > 95% noted for any variable pairs as confirmed using the preprocessing summaries from the <mark style="background-color: #CCECFF">**caret**</mark> and <mark style="background-color: #CCECFF">**lares**</mark> packages.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.3, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DPA <- peakVO2

##################################
# Listing all predictors
##################################
DPA.Predictors <- DPA[,!names(DPA) %in% c("died","ttodead")]

##################################
# Listing all numeric predictors
##################################
DPA.Predictors.Numeric <- DPA.Predictors[,sapply(DPA.Predictors, is.numeric)]

##################################
# Visualizing pairwise correlation between predictors
##################################
DPA_CorrelationTest <- cor.mtest(DPA.Predictors.Numeric,
                       method = "pearson",
                       conf.level = .95)

corrplot(cor(DPA.Predictors.Numeric,
             method = "pearson",
             use="pairwise.complete.obs"), 
         method = "circle",
         type = "upper", 
         order = "original", 
         tl.col = "black", 
         tl.cex = 0.75,
         tl.srt = 90, 
         sig.level = 0.05, 
         p.mat = DPA_CorrelationTest$p,
         insig = "blank")



##################################
# Identifying the highly correlated variables
##################################
DPA_Correlation <-  cor(DPA.Predictors.Numeric, 
                        method = "pearson",
                        use="pairwise.complete.obs")
(DPA_HighlyCorrelatedCount <- sum(abs(DPA_Correlation[upper.tri(DPA_Correlation)]) > 0.95))

if (DPA_HighlyCorrelatedCount == 0) {
  print("No highly correlated predictors noted.")
} else {
  print(paste0("High correlation observed for ",
               (DPA_HighlyCorrelatedCount),
               " pairs of numeric variable(s) with Correlation.Coefficient>0.95."))
  
  (DPA_HighlyCorrelatedPairs <- corr_cross(DPA.Predictors.Numeric,
  max_pvalue = 0.05, 
  top = DPA_HighlyCorrelatedCount,
  rm.na = TRUE,
  grid = FALSE
))
  
}


if (DPA_HighlyCorrelatedCount > 0) {
  DPA_HighlyCorrelated <- findCorrelation(DPA_Correlation, cutoff = 0.95)
  
  (DPA_HighlyCorrelatedForRemoval <- length(DPA_HighlyCorrelated))
  
  print(paste0("High correlation can be resolved by removing ",
               (DPA_HighlyCorrelatedForRemoval),
               " numeric variable(s)."))
  
  for (j in 1:DPA_HighlyCorrelatedForRemoval) {
  DPA_HighlyCorrelatedRemovedVariable <- colnames(DPA.Predictors.Numeric)[DPA_HighlyCorrelated[j]]
  print(paste0("Variable ",
               j,
               " for removal: ",
               DPA_HighlyCorrelatedRemovedVariable))
  }
  
  ##################################
  # Filtering out columns with high correlation
  #################################
  DPA_ExcludedHighCorrelation <- DPA[,-DPA_HighlyCorrelated]
  
  ##################################
  # Gathering descriptive statistics
  ##################################
  (DPA_ExcludedHighCorrelation_Skimmed <- skim(DPA_ExcludedHighCorrelation))

}

```

</details>

###  1.3.4 Linear Dependencies
|
| Linear dependency data assessment:
|
| **[A]** No linear dependencies noted for any subset of variables using the preprocessing summary from the <mark style="background-color: #CCECFF">**caret**</mark> package applying the <span style="color: #0000FF">findLinearCombos</span> method which utilizes the QR decomposition of a matrix to enumerate sets of linear combinations (if they exist). 
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.4, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
DPA <- peakVO2

##################################
# Listing all predictors
##################################
DPA.Predictors <- DPA[,!names(DPA) %in% c("died","ttodead")]

##################################
# Listing all numeric predictors
##################################
DPA.Predictors.Numeric <- DPA.Predictors[,sapply(DPA.Predictors, is.numeric)]

##################################
# Identifying the linearly dependent variables
##################################
DPA_LinearlyDependent <- findLinearCombos(DPA.Predictors.Numeric)

(DPA_LinearlyDependentCount <- length(DPA_LinearlyDependent$linearCombos))

if (DPA_LinearlyDependentCount == 0) {
  print("No linearly dependent predictors noted.")
} else {
  print(paste0("Linear dependency observed for ",
               (DPA_LinearlyDependentCount),
               " subset(s) of numeric variable(s)."))
  
  for (i in 1:DPA_LinearlyDependentCount) {
    DPA_LinearlyDependentSubset <- colnames(DPA.Predictors.Numeric)[DPA_LinearlyDependent$linearCombos[[i]]]
    print(paste0("Linear dependent variable(s) for subset ",
                 i,
                 " include: ",
                 DPA_LinearlyDependentSubset))
  }
  
}

##################################
# Identifying the linearly dependent variables for removal
##################################

if (DPA_LinearlyDependentCount > 0) {
  DPA_LinearlyDependent <- findLinearCombos(DPA.Predictors.Numeric)
  
  DPA_LinearlyDependentForRemoval <- length(DPA_LinearlyDependent$remove)
  
  print(paste0("Linear dependency can be resolved by removing ",
               (DPA_LinearlyDependentForRemoval),
               " numeric variable(s)."))
  
  for (j in 1:DPA_LinearlyDependentForRemoval) {
  DPA_LinearlyDependentRemovedVariable <- colnames(DPA.Predictors.Numeric)[DPA_LinearlyDependent$remove[j]]
  print(paste0("Variable ",
               j,
               " for removal: ",
               DPA_LinearlyDependentRemovedVariable))
  }
  
  ##################################
  # Filtering out columns with linear dependency
  #################################
  DPA_ExcludedLinearlyDependent <- DPA[,-DPA_LinearlyDependent$remove]
  
  ##################################
  # Gathering descriptive statistics
  ##################################
  (DPA_ExcludedLinearlyDependent_Skimmed <- skim(DPA_ExcludedLinearlyDependent))

}

```

</details>

###  1.3.5 Univariate Filter
|
| **[A]** 25 variables were evaluated as statistically significant predictors from the univariate Cox Proportional Hazards modelling analysis with p-value=<0.05.
|      **[A.1]** <span style="color: #FF0000">age</span> variable (numeric)
|      **[A.2]** <span style="color: #FF0000">betablok</span> variable (factor)
|      **[A.3]** <span style="color: #FF0000">acei</span> variable (factor)
|      **[A.4]** <span style="color: #FF0000">angioten.II</span> variable (factor)
|      **[A.5]** <span style="color: #FF0000">anti.arrhy</span> variable (factor)
|      **[A.6]** <span style="color: #FF0000">anti.coag</span> variable (factor)
|      **[A.7]** <span style="color: #FF0000">aspirin</span> variable (factor)
|      **[A.8]** <span style="color: #FF0000">vasodilator</span> variable (factor)
|      **[A.9]** <span style="color: #FF0000">diuretic.loop</span> variable (factor)
|      **[A.10]** <span style="color: #FF0000">diuretic.thiazide</span> variable (factor)
|      **[A.11]** <span style="color: #FF0000">insulin</span> variable (factor)
|      **[A.12]** <span style="color: #FF0000">surgery.pacemaker</span> variable (factor)
|      **[A.13]** <span style="color: #FF0000">surgery.cabg</span> variable (factor)
|      **[A.14]** <span style="color: #FF0000">resting.systolic.bp</span> variable (numeric)
|      **[A.15]** <span style="color: #FF0000">resting.hr</span> variable (numeric)
|      **[A.16]** <span style="color: #FF0000">lvef.metabl</span> variable (numeric)
|      **[A.17]** <span style="color: #FF0000">peak.vo2</span> variable (numeric)
|      **[A.18]** <span style="color: #FF0000">interval</span> variable (numeric)
|      **[A.19]** <span style="color: #FF0000">cad</span> variable (factor)
|      **[A.20]** <span style="color: #FF0000">bun</span> variable (numeric)
|      **[A.21]** <span style="color: #FF0000">sodium</span> variable (numeric)
|      **[A.22]** <span style="color: #FF0000">hgb</span> variable (numeric)
|      **[A.23]** <span style="color: #FF0000">glucose</span> variable (numeric)
|      **[A.24]** <span style="color: #FF0000">male</span> variable (factor)
|      **[A.25]** <span style="color: #FF0000">crcl</span> variable (numeric)
| **[B]** 14 variables were evaluated as not statistically significant predictors from the univariate Cox Proportional Hazards modelling analysis with p-value>0.05.
|      **[B.1]** <span style="color: #FF0000">dilver</span> variable (factor)
|      **[B.2]** <span style="color: #FF0000">nifed</span> variable (factor)
|      **[B.3]** <span style="color: #FF0000">digoxin</span> variable (factor)
|      **[B.4]** <span style="color: #FF0000">nitrates</span> variable (factor)
|      **[B.5]** <span style="color: #FF0000">diuretic.potassium.spar</span> variable (factor)
|      **[B.6]** <span style="color: #FF0000">lipidrx.statin</span> variable (factor)
|      **[B.7]** <span style="color: #FF0000">surgery.pci</span> variable (factor)
|      **[B.8]** <span style="color: #FF0000">surgery.aicd.implant</span> variable (factor)
|      **[B.9]** <span style="color: #FF0000">smknow</span> variable (factor)
|      **[B.10]** <span style="color: #FF0000">q.wave.mi</span> variable (factor)
|      **[B.11]** <span style="color: #FF0000">bmi</span> variable (numeric)
|      **[B.12]** <span style="color: #FF0000">niddm</span> variable (factor)
|      **[B.13]** <span style="color: #FF0000">peak.rer</span> variable (numeric)
|      **[B.14]** <span style="color: #FF0000">black</span> variable (factor)
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.5, warning=FALSE, message=FALSE}
##################################
# Formulating the univariate Cox PH models
# to assess the predictive power
# of the individual predictors
##################################

##################################
# Loading dataset
##################################
UF <- peakVO2.Source

##################################
# Formulating the response 
# and predictor variables
##################################
UF_Response <- Surv(time=UF$ttodead, event=UF$died)

UF_Predictors <- names(UF)[!names(UF) %in% c("ttodead","died")]

##################################
# Formulating the response 
# and predictor variables
##################################

(UF_CoxPHFormula <- sapply(UF_Predictors,
                          function(x) as.formula(paste('Surv(ttodead,died)~', x))))

(UF_CoxPHModel <- lapply(UF_CoxPHFormula, function(x){coxph(x, data=UF)}))

UF_CoxPHModelResults <- lapply(UF_CoxPHModel,
                               function(x){
                                 x <- summary(x)
                                 p.value<-round(x$wald["pvalue"], digits=5)
                                 wald.test<-round(x$wald["test"], digits=5)
                                 
                                 ######################################
                                 # Extracting the concordance values
                                 ######################################
                                 concordance<-round(x$concordance[[1]],digits=5)
                                 
                                 ######################################
                                 # Extracting the beta coefficients
                                 ######################################
                                 beta<-round(x$coef[1], digits=5)
                                 z<-round(x$coefficients[[4]], digits=5)
                                 
                                 ######################################
                                 # Extracting the exponentiated coefficients
                                 ######################################
                                 HR <-round(x$coef[2], digits=5)
                                 HR.confint.lower <- round(x$conf.int[,"lower .95"],5)
                                 HR.confint.upper <- round(x$conf.int[,"upper .95"],5)
                                 HR <- paste0(HR, " (",
                                              HR.confint.lower, "-", HR.confint.upper, ")")
                                 
                                 ######################################                      
                                 # Consolidating the model results
                                 ######################################
                                 res<-c(concordance,beta, HR, z, p.value, wald.test)
                                 names(res)<-c("Concordance",
                                               "Beta",
                                               "HR (95% CI for HR)",
                                               "z",
                                               "P-Value",
                                               "Wald Test")
                                 return(res)
                       })

UF_CoxPHModelResults <- t(as.data.frame(UF_CoxPHModelResults, check.names = FALSE))

######################################                      
# Summarizing the results
# for all variables
######################################
UF_CoxPHModelSummary <- as.data.frame(UF_CoxPHModelResults)

######################################                      
# Gathering only 
# the significant variables
# from the univariate Cox PH analysis
######################################
(UF_CoxPHModelSummary_Sig <- UF_CoxPHModelSummary[UF_CoxPHModelSummary$'P-Value'==0.05 |
                                                   UF_CoxPHModelSummary$'P-Value'<0.05,])

nrow(UF_CoxPHModelSummary_Sig)

rownames(UF_CoxPHModelSummary_Sig)

UF_Sig <- peakVO2[,rownames(UF_CoxPHModelSummary_Sig)]

(data.frame(
  Column.Index=c(1:length(names(UF_Sig))),
  Column.Name= names(UF_Sig),
  Column.Type=sapply(UF_Sig, function(x) class(x)),
  row.names=NULL)
)

######################################                      
# Gathering only 
# the non-significant variables
# from the univariate Cox PH analysis
######################################
(UF_CoxPHModelSummary_NonSig <- UF_CoxPHModelSummary[UF_CoxPHModelSummary$'P-Value'>0.05,])

nrow(UF_CoxPHModelSummary_NonSig)

rownames(UF_CoxPHModelSummary_NonSig)

UF_NonSig <- peakVO2[,rownames(UF_CoxPHModelSummary_NonSig)]

(data.frame(
  Column.Index=c(1:length(names(UF_NonSig))),
  Column.Name= names(UF_NonSig),
  Column.Type=sapply(UF_NonSig, function(x) class(x)),
  row.names=NULL)
)

```

</details>

###  1.3.6 Pre-Processed Dataset
|
| Preliminary dataset assessment:
|
| **[A]** 2231 rows (observations)
| 
| **[B]** 27 columns (variables)
|      **[B.1]** 1/27 survival event status = <span style="color: #FF0000">died</span> variable (factor)
|             **[B.1.1]** Event = <span style="color: #FF0000">died=1</span> 
|             **[B.1.2]** Censored or Non-Event = <span style="color: #FF0000">died=0</span>
|      **[B.2]** 1/27 survival time = <span style="color: #FF0000">ttodead</span> variable (numeric)
|      **[B.3]** 25/27 predictors = All remaining variables (14/25 factor + 11/25 numeric)
|
| **[C]** Pre-processing actions applied:
|      **[C.1]** No centering, scaling and shape transformation applied to maintain interpretability
|      **[C.2]** No outlier treatment applied since the high values noted were contextually valid and sensible 
|      **[C.3]** 2 predictors removed due to zero or near-zero variance 
|      **[C.4]** No predictors removed due to high correlation
|      **[C.5]** No predictors removed due to linear dependencies
|      **[C.6]** 14 predictors evaluated as not statistically significant predictors from the univariate Cox Proportional Hazards modelling analysis removed
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.3.6, warning=FALSE, message=FALSE}
##################################
# Filtering out columns noted with data quality issues including
# zero and near-zero variance,
# to create the pre-modelling dataset
##################################
PMA_ExcludedNonSig <- peakVO2[,!names(peakVO2) %in% rownames(UF_CoxPHModelSummary_NonSig)]

PMA_PreModelling_Train <- PMA_ExcludedNonSig

##################################
# Gathering descriptive statistics
##################################
(PMA_PreModelling_Train_Skimmed <- skim(PMA_PreModelling_Train))

###################################
# Verifying the data dimensions
# for the train set
###################################
dim(PMA_PreModelling_Train)

```

</details>

## 1.4 Data Exploration
|
| Exploratory data analysis:
|
| **[A]** Numeric variables which demonstrated differential relationships with the <span style="color: #FF0000">ttodead</span> and <span style="color: #FF0000">died</span> survival time and event status variables, based on trend line correlation with survival time, include:
|      **[A.1]** <span style="color: #FF0000">peak.vo2</span> variable (numeric)
|      **[A.2]** <span style="color: #FF0000">interval</span> variable (numeric)
|      **[A.3]** <span style="color: #FF0000">sodium</span> variable (numeric)
|
| **[B]** Factor variables which demonstrated differential relationships with the <span style="color: #FF0000">ttodead</span> and <span style="color: #FF0000">died</span> survival time and event status variables, based on the Log-Rank Test p-value and estimated Kaplan-Meier survival curve separations, include:
|      **[B.1]** <span style="color: #FF0000">betablk</span> variable (factor)
|      **[B.2]** <span style="color: #FF0000">diuretic.thiazide</span> variable (factor)
|      **[B.3]** <span style="color: #FF0000">cad</span> variable (factor)
|      **[B.4]** <span style="color: #FF0000">diuretic.loop</span> variable (factor)
|      **[B.5]** <span style="color: #FF0000">male</span> variable (factor)
|      **[B.6]** <span style="color: #FF0000">surgery.cabg</span> variable (factor)
|      **[B.7]** <span style="color: #FF0000">insulin</span> variable (factor)
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.4, warning=FALSE, message=FALSE}
##################################
# Loading dataset
##################################
EDA <- PMA_PreModelling_Train

##################################
# Loading dataset
##################################
EDA.DescriptiveStatistics <- EDA

EDA.DescriptiveStatistics$died <- ifelse(EDA.DescriptiveStatistics$died=="0","Survived+Censored","Died")

##################################
# Formulating a preliminary summary
# of descriptive statistics 
##################################
EDA.DescriptiveStatistics %>%
  tbl_summary(
    by = died,
    type = all_continuous() ~ "continuous2",
    statistic = all_continuous() ~ c("{N_nonmiss}",
                                     "{mean} ({sd})", 
                                     "{median} ({p25}, {p75})", 
                                     "{min}, {max}"),
    missing = "no") %>% 
  add_overall() %>% 
  add_p()

##################################
# Listing all predictors
##################################
EDA.Predictors <- EDA[,!names(EDA) %in% c("died","ttodead")]


##################################
# Listing all numeric predictors
##################################
EDA.Predictors.Numeric <- EDA.Predictors[,sapply(EDA.Predictors, is.numeric)]
ncol(EDA.Predictors.Numeric)
names(EDA.Predictors.Numeric)

##################################
# Listing all factor predictors
##################################
EDA.Predictors.Factor <- EDA.Predictors[,sapply(EDA.Predictors, is.factor)]
ncol(EDA.Predictors.Factor)
names(EDA.Predictors.Factor)

##################################
# Formulating the box plots
##################################
featurePlot(x = EDA.Predictors.Numeric, 
            y = EDA$died,
            plot = "box",
            scales = list(x = list(relation="free", rot = 90), 
                          y = list(relation="free")),
            adjust = 1.5, 
            pch = "|")

##################################
# Formulating the scatter plot
##################################
featurePlot(x = EDA.Predictors.Numeric, 
            y = EDA$ttodead,
            plot = "scatter",
            type = c("p", "smooth"),
            span = .5)

##################################
# Restructuring the dataset for
# for barchart analysis
##################################
died <- EDA$died
EDA.Bar.Source <- as.data.frame(cbind(died,
                     EDA.Predictors.Factor))
ncol(EDA.Bar.Source)
names(EDA.Bar.Source)


##################################
# Creating a function to formulate
# the proportions table
##################################
EDA.PropTable.Function <- function(FactorVar) {
  EDA.Bar.Source.FactorVar <- EDA.Bar.Source[,c("died",
                                          FactorVar)]
  EDA.Bar.Source.FactorVar.Prop <- as.data.frame(prop.table(table(EDA.Bar.Source.FactorVar), 2))
  names(EDA.Bar.Source.FactorVar.Prop)[2] <- "Structure"
  EDA.Bar.Source.FactorVar.Prop$Variable <- rep(FactorVar,nrow(EDA.Bar.Source.FactorVar.Prop))

  return(EDA.Bar.Source.FactorVar.Prop)

}


EDA.Bar.Source.FactorVar.Prop.Group <- rbind(EDA.PropTable.Function(names(EDA.Bar.Source)[2]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[3]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[4]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[5]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[6]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[7]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[8]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[9]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[10]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[11]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[12]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[13]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[14]),
                                              EDA.PropTable.Function(names(EDA.Bar.Source)[15]))

(EDA.Barchart.FactorVar <- barchart(EDA.Bar.Source.FactorVar.Prop.Group[,3] ~
                                      EDA.Bar.Source.FactorVar.Prop.Group[,2] | EDA.Bar.Source.FactorVar.Prop.Group[,4],
                                      data=EDA.Bar.Source.FactorVar.Prop.Group,
                                      groups = EDA.Bar.Source.FactorVar.Prop.Group[,1],
                                      stack=TRUE,
                                      ylab = "Proportion",
                                      xlab = "Structure",
                                      auto.key = list(adj = 1),
                                      layout=(c(5,3))))

##################################
# Formulating the Kaplan-Meier plots
# for the categorical variables
##################################
KM_PreModelling_Train <- PMA_PreModelling_Train
KM_PreModelling_Train$died <- as.numeric(KM_PreModelling_Train$died )

KM_betablok <- survfit(Surv(ttodead, died) ~ betablok,
                      data=KM_PreModelling_Train)
KMPlot_betablok <- ggsurvplot(KM_betablok,
                            xlab="Survival Time",
                            ylab="Survival Probability",
                            break.time.by=12,
                            ggtheme=theme_bw(),
                            fontsize=3,
                            pval.size=3,
                            pval=TRUE)

KM_aspirin <- survfit(Surv(ttodead, died) ~ aspirin,
                      data=KM_PreModelling_Train)
KMPlot_aspirin <- ggsurvplot(KM_aspirin,
                            xlab="Survival Time",
                            ylab="Survival Probability",
                            break.time.by=12,
                            ggtheme=theme_bw(),
                            fontsize=3,
                            pval.size=3,
                            pval=TRUE)

KM_anti.coag <- survfit(Surv(ttodead, died) ~ anti.coag,
                      data=KM_PreModelling_Train)
KMPlot_anti.coag <- ggsurvplot(KM_anti.coag,
                            xlab="Survival Time",
                            ylab="Survival Probability",
                            break.time.by=12,
                            ggtheme=theme_bw(),
                            fontsize=3,
                            pval.size=3,
                            pval=TRUE)

KM_anti.arrhy <- survfit(Surv(ttodead, died) ~ anti.arrhy,
                      data=KM_PreModelling_Train)
KMPlot_anti.arrhy <- ggsurvplot(KM_anti.arrhy,
                            xlab="Survival Time",
                            ylab="Survival Probability",
                            break.time.by=12,
                            ggtheme=theme_bw(),
                            fontsize=3,
                            pval.size=3,
                            pval=TRUE)

KM_angioten.II <- survfit(Surv(ttodead, died) ~ angioten.II,
                      data=KM_PreModelling_Train)
KMPlot_angioten.II <- ggsurvplot(KM_angioten.II,
                            xlab="Survival Time",
                            ylab="Survival Probability",
                            break.time.by=12,
                            ggtheme=theme_bw(),
                            fontsize=3,
                            pval.size=3,
                            pval=TRUE)

KM_acei <- survfit(Surv(ttodead, died) ~ acei,
                      data=KM_PreModelling_Train)
KMPlot_acei <- ggsurvplot(KM_acei,
                            xlab="Survival Time",
                            ylab="Survival Probability",
                            break.time.by=12,
                            ggtheme=theme_bw(),
                            fontsize=3,
                            pval.size=3,
                            pval=TRUE)

KM_diuretic.thiazide <- survfit(Surv(ttodead, died) ~ diuretic.thiazide,
                      data=KM_PreModelling_Train)
KMPlot_diuretic.thiazide <- ggsurvplot(KM_diuretic.thiazide,
                            xlab="Survival Time",
                            ylab="Survival Probability",
                            break.time.by=12,
                            ggtheme=theme_bw(),
                            fontsize=3,
                            pval.size=3,
                            pval=TRUE)

KM_diuretic.loop <- survfit(Surv(ttodead, died) ~ diuretic.loop,
                      data=KM_PreModelling_Train)
KMPlot_diuretic.loop <- ggsurvplot(KM_diuretic.loop,
                            xlab="Survival Time",
                            ylab="Survival Probability",
                            break.time.by=12,
                            ggtheme=theme_bw(),
                            fontsize=3,
                            pval.size=3,
                            pval=TRUE)

KM_cad <- survfit(Surv(ttodead, died) ~ cad,
                      data=KM_PreModelling_Train)
KMPlot_cad <- ggsurvplot(KM_cad,
                            xlab="Survival Time",
                            ylab="Survival Probability",
                            break.time.by=12,
                            ggtheme=theme_bw(),
                            fontsize=3,
                            pval.size=3,
                            pval=TRUE)

KM_male <- survfit(Surv(ttodead, died) ~ male,
                      data=KM_PreModelling_Train)
KMPlot_male <- ggsurvplot(KM_male,
                            xlab="Survival Time",
                            ylab="Survival Probability",
                            break.time.by=12,
                            ggtheme=theme_bw(),
                            fontsize=3,
                            pval.size=3,
                            pval=TRUE)

KM_insulin <- survfit(Surv(ttodead, died) ~ insulin,
                      data=KM_PreModelling_Train)
KMPlot_insulin <- ggsurvplot(KM_insulin,
                            xlab="Survival Time",
                            ylab="Survival Probability",
                            break.time.by=12,
                            ggtheme=theme_bw(),
                            fontsize=3,
                            pval.size=3,
                            pval=TRUE)

KM_vasodilator <- survfit(Surv(ttodead, died) ~ vasodilator,
                      data=KM_PreModelling_Train)
KMPlot_vasodilator <- ggsurvplot(KM_vasodilator,
                            xlab="Survival Time",
                            ylab="Survival Probability",
                            break.time.by=12,
                            ggtheme=theme_bw(),
                            fontsize=3,
                            pval.size=3,
                            pval=TRUE)

KM_surgery.pacemaker <- survfit(Surv(ttodead, died) ~ surgery.pacemaker,
                      data=KM_PreModelling_Train)
KMPlot_surgery.pacemaker <- ggsurvplot(KM_surgery.pacemaker,
                            xlab="Survival Time",
                            ylab="Survival Probability",
                            break.time.by=12,
                            ggtheme=theme_bw(),
                            fontsize=3,
                            pval.size=3,
                            pval=TRUE)

KM_surgery.cabg <- survfit(Surv(ttodead, died) ~ surgery.cabg,
                      data=KM_PreModelling_Train)
KMPlot_surgery.cabg <- ggsurvplot(KM_surgery.cabg,
                            xlab="Survival Time",
                            ylab="Survival Probability",
                            break.time.by=12,
                            ggtheme=theme_bw(),
                            fontsize=3,
                            pval.size=3,
                            pval=TRUE)

KMPlot_List <- list()
KMPlot_List[[1]] <- KMPlot_betablok
KMPlot_List[[2]] <- KMPlot_acei
KMPlot_List[[3]] <- KMPlot_angioten.II
KMPlot_List[[4]] <- KMPlot_anti.arrhy
KMPlot_List[[5]] <- KMPlot_anti.coag
KMPlot_List[[6]] <- KMPlot_aspirin
KMPlot_List[[7]] <- KMPlot_vasodilator
KMPlot_List[[8]] <- KMPlot_diuretic.loop
KMPlot_List[[9]] <- KMPlot_diuretic.thiazide
KMPlot_List[[10]] <- KMPlot_insulin
KMPlot_List[[11]] <- KMPlot_surgery.pacemaker
KMPlot_List[[12]] <- KMPlot_surgery.cabg
KMPlot_List[[13]] <- KMPlot_cad
KMPlot_List[[14]] <- KMPlot_male

arrange_ggsurvplots(KMPlot_List,
                    ncol=3,
                    nrow=5)

```

</details>

## 1.5 Penalized Survival Models

###  1.5.1 Least Absolute Shrinkage and Selection Operator (LASSO)
|
| [Least Absolute Shrinkage and Selection Operator Regression](https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1996.tb02080.x) is a regularization technique aimed at encouraging sparsity in the model by imposing a penalty on the absolute values of the regression coefficients. The algorithm adds a penalty term (referred to as the L1 regularization) defined as the sum of the absolute values of the regression coefficients multiplied by a tuning parameter lambda which controls the amount of penalty applied. The method formulates an optimization problem that minimizes the negative log-partial likelihood of the Cox proportional hazards model subject to the penalty terms. The optimization problem is solved using coordinate descent or least-angle regression, by iteratively updating regression coefficients, while incorporating the LASSO penalty. This approach can be useful for feature selection, as it tends to shrink the coefficients of less important predictor variables to zero, which can help simplify the model and improve its interpretability.
|
| **[A]** The multivariate Cox proportional hazards regression model from the  <mark style="background-color: #CCECFF">**survival**</mark> package was implemented with the LASSO penalty function applied using the <mark style="background-color: #CCECFF">**hdnom**</mark>, <mark style="background-color: #CCECFF">**penalized**</mark> and <mark style="background-color: #CCECFF">**glmnet**</mark> packages. 
|
| **[B]** The method contains 2 hyperparameters:
|      **[B.1]** <span style="color: #FF0000">nfolds</span> = fold numbers of cross-validation fixed at a value = 5
|      **[B.2]** <span style="color: #FF0000">rule</span> = model selection criterion fixed at a setting of optimal lambda such that error is within 1 standard error of the minimum
|
| **[C]** The method selected 5 out of the 25 predictors for the final Cox Proportional Hazards model as follows:
|      **[C.1]** <span style="color: #FF0000">betablok</span> variable (factor)
|      **[C.2]** <span style="color: #FF0000">peak.vo2</span> variable (numeric)
|      **[C.3]** <span style="color: #FF0000">interval</span> variable (numeric)
|      **[C.4]** <span style="color: #FF0000">bun</span> variable (numeric)
|      **[C.5]** <span style="color: #FF0000">male</span> variable (factor)
|
| **[D]** Optimal model parameter was  was determined as:
|      **[D.1]** Lambda = 0.061
|
| **[E]** Internally validated Time-Dependent AUROC metrics using bootstrap resampling of the train data showed good performance overall except for the last few time periods and are summarized as follows:
|      **[E.1]** 12 months = 0.75935
|      **[E.2]** 24 months = 0.76467
|      **[E.3]** 36 months = 0.65817
|      **[E.4]** 48 months = 0.66612
|      **[E.5]** 60 months = 0.65673
|      **[E.6]** 72 months = 0.67133
|      **[E.7]** 84 months = 0.71603
|      **[E.8]** 96 months = 0.59719
|      **[E.9]** 108 months = 0.67066
|      **[E.10]** 120 months = 0.56227
|
| **[F]** Externally validated Time-Dependent AUROC metrics using the test data showed good performance overall except for the last few time periods and are summarized as follows:
|      **[F.1]** 12 months = 0.75529
|      **[F.2]** 24 months = 0.74168
|      **[F.3]** 36 months = 0.63662
|      **[F.4]** 48 months = 0.62143
|      **[F.5]** 60 months = 0.65494
|      **[F.6]** 72 months = 0.67220
|      **[F.7]** 84 months = 0.65163
|      **[F.8]** 96 months = 0.73170
|      **[F.9]** 108 months = 0.34070
|      **[F.10]** 120 months = 0.32500
|
| **[G]** Model predictions at time = 60 months were reasonably calibrated for both the train and test data. Kaplan-Meier survival curves for the three risk groups from the calibration data were differentially profiled with p-value < 0.05. 
|
| **[H]** Model predictions at time = 120 months were reasonably calibrated for both the train and test data. Kaplan-Meier survival curves for the three risk groups from the calibration data were differentially profiled with p-value < 0.05.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.5.1, warning=FALSE, message=FALSE}
##################################
# Loading the preprocessed data
##################################
PMA_PreModelling_LASSO <- peakVO2.Source[,!names(peakVO2.Source) %in% rownames(UF_CoxPHModelSummary_NonSig)]

##################################
# Setting the appropriate variable types
##################################
PMA_PreModelling_LASSO$died <- as.factor(PMA_PreModelling_LASSO$died)

##################################
# Creating a local object
# for the train and test sets
##################################
set.seed(88888888)
TrainIndex <- createDataPartition(PMA_PreModelling_LASSO$died, 
                                  p = 0.8, 
                                  list = FALSE, 
                                  times = 1)

PMA_PreModelling_LASSO_Train <- PMA_PreModelling_LASSO[ TrainIndex,]
PMA_PreModelling_LASSO_Test  <- PMA_PreModelling_LASSO[-TrainIndex,]

PMA_PreModelling_LASSO_Train$died <- as.numeric(PMA_PreModelling_LASSO_Train$died)
PMA_PreModelling_LASSO_Test$died  <- as.numeric(PMA_PreModelling_LASSO_Test$died)

##################################
# Formulating the model components
# for the train data
##################################
LASSO_Train_Predictors <- as.matrix(
  PMA_PreModelling_LASSO_Train[,!names(PMA_PreModelling_LASSO_Train) 
                               %in% c("ttodead","died")])
LASSO_Train_Time    <- PMA_PreModelling_LASSO_Train$ttodead
LASSO_Train_Status  <- PMA_PreModelling_LASSO_Train$died
LASSO_Train_Response <- survival::Surv(LASSO_Train_Time, LASSO_Train_Status)

##################################
# Fitting a LASSO model
##################################
LASSO_Train_CoxPH_Fit <- fit_lasso(LASSO_Train_Predictors,
                              LASSO_Train_Response,
                              nfolds = 5,
                              rule = "lambda.1se",
                              seed = 88888888)

##################################
# Extracting the model objects and
# optimal hyperparameters
# from the LASSO model
##################################
(LASSO_Train_CoxPH_Model  <- LASSO_Train_CoxPH_Fit$model)
(LASSO_Train_CoxPH_Model  <- LASSO_Train_CoxPH_Fit$model$beta)
(LASSO_Train_CoxPH_Lambda <- LASSO_Train_CoxPH_Fit$lambda)

##################################
# Conducting an internal validation
# of the LASSO model
# using a 50-cycle bootstrap
##################################
LASSO_Train_CoxPH_Model_InternalValidation <- validate(LASSO_Train_Predictors,
                                                       LASSO_Train_Time,
                                                       LASSO_Train_Status,
                                                       model.type = "lasso",
                                                       alpha = 1,
                                                       lambda = LASSO_Train_CoxPH_Fit$lambda,
                                                       method = "bootstrap",
                                                       boot.times = 50,
                                                       tauc.type = "UNO",
                                                       tauc.time = seq(12, 120, 12),
                                                       seed = 88888888)

print(LASSO_Train_CoxPH_Model_InternalValidation)

summary(LASSO_Train_CoxPH_Model_InternalValidation)

LASSO_Train_IV_Summary <- data.frame(matrix(ncol=4, nrow=10))
names(LASSO_Train_IV_Summary) <- c("Model","Validation","MedianTDAUROC","Time")

for (i in 1:10){
  LASSO_Train_IV_Summary[i,1] <- "LASSO"
  LASSO_Train_IV_Summary[i,2] <- "Cross-Validation"
  LASSO_Train_IV_Summary[i,3] <- summary(LASSO_Train_CoxPH_Model_InternalValidation)[[4,i]] 
  LASSO_Train_IV_Summary[i,4] <- i*12 
}

LASSO_Train_IV_Summary

plot(LASSO_Train_CoxPH_Model_InternalValidation, 
     ylim = c(0, 1))

##################################
# Conducting an external validation
# of the LASSO model
# using the test data
##################################
LASSO_Test_Predictors <- as.matrix(
  PMA_PreModelling_LASSO_Test[,!names(PMA_PreModelling_LASSO_Test)
                               %in% c("ttodead","died")])
LASSO_Test_Time    <- PMA_PreModelling_LASSO_Test$ttodead
LASSO_Test_Status  <- PMA_PreModelling_LASSO_Test$died
LASSO_Test_Response <- survival::Surv(LASSO_Test_Time, LASSO_Test_Status)

LASSO_Train_CoxPH_Model_ExternalValidation <- validate_external(LASSO_Train_CoxPH_Fit,
                                                       LASSO_Train_Predictors,
                                                       LASSO_Train_Time,
                                                       LASSO_Train_Status,
                                                       LASSO_Test_Predictors,
                                                       LASSO_Test_Time,
                                                       LASSO_Test_Status,
                                                       tauc.type = "UNO",
                                                       tauc.time = seq(12, 120, 12))

print(LASSO_Train_CoxPH_Model_ExternalValidation)

summary(LASSO_Train_CoxPH_Model_ExternalValidation)

LASSO_Train_EV_Summary <- data.frame(matrix(ncol=4, nrow=10))
names(LASSO_Train_EV_Summary) <- c("Model","Validation","MedianTDAUROC","Time")

for (i in 1:10){
  LASSO_Train_EV_Summary[i,1] <- "LASSO"
  LASSO_Train_EV_Summary[i,2] <- "Test"
  LASSO_Train_EV_Summary[i,3] <- summary(LASSO_Train_CoxPH_Model_ExternalValidation)[[1,i]] 
  LASSO_Train_EV_Summary[i,4] <- i*12 
}

LASSO_Train_EV_Summary

plot(LASSO_Train_CoxPH_Model_ExternalValidation, 
     ylim = c(0, 1))

##################################
# Conducting an internal calibration
# of the LASSO model
# using a 50-cycle bootstrap
# for Year 5 (Time = 60)
##################################
LASSO_Train_CoxPH_Model_InternalCalibration <- calibrate(LASSO_Train_Predictors,
                                                       LASSO_Train_Time,
                                                       LASSO_Train_Status,
                                                       model.type = "lasso",
                                                       alpha = 1,
                                                       lambda = LASSO_Train_CoxPH_Fit$lambda,
                                                       method = "bootstrap",
                                                       boot.times = 50,
                                                       pred.at = 60,
                                                       ngroup = 3,
                                                       seed = 88888888)

print(LASSO_Train_CoxPH_Model_InternalCalibration)

summary(LASSO_Train_CoxPH_Model_InternalCalibration)

plot(LASSO_Train_CoxPH_Model_InternalCalibration)

##################################
# Estimating survival curves
# of the LASSO model
# for the risk groups
# using the train data
##################################
LASSO_Train_CoxPH_Model_KMPlot <- kmplot( LASSO_Train_CoxPH_Model_InternalCalibration,
                                          group.name = c("High-Risk", "Medium-Risk", "Low-Risk"),
                                          time.at = 1:10 * 12)

##################################
# Conducting an internal calibration
# of the LASSO model
# using a 50-cycle bootstrap
# for Year 10 (Time = 120)
##################################
LASSO_Train_CoxPH_Model_InternalCalibration <- calibrate(LASSO_Train_Predictors,
                                                       LASSO_Train_Time,
                                                       LASSO_Train_Status,
                                                       model.type = "lasso",
                                                       alpha = 1,
                                                       lambda = LASSO_Train_CoxPH_Fit$lambda,
                                                       method = "bootstrap",
                                                       boot.times = 50,
                                                       pred.at = 120,
                                                       ngroup = 3,
                                                       seed = 88888888)

print(LASSO_Train_CoxPH_Model_InternalCalibration)

summary(LASSO_Train_CoxPH_Model_InternalCalibration)

plot(LASSO_Train_CoxPH_Model_InternalCalibration)

##################################
# Estimating survival curves
# of the LASSO model
# for the risk groups
# using the train data
##################################
LASSO_Train_CoxPH_Model_KMPlot <- kmplot( LASSO_Train_CoxPH_Model_InternalCalibration,
                                          group.name = c("High-Risk", "Medium-Risk", "Low-Risk"),
                                          time.at = 1:10 * 12)

##################################
# Conducting an external calibration
# of the LASSO model
# using the test data
# for Year 5 (Time = 60)
##################################
LASSO_Train_CoxPH_Model_ExternalCalibration <- calibrate_external(LASSO_Train_CoxPH_Fit,
                                                       LASSO_Train_Predictors,
                                                       LASSO_Train_Time,
                                                       LASSO_Train_Status,
                                                       LASSO_Test_Predictors,
                                                       LASSO_Test_Time,
                                                       LASSO_Test_Status,
                                                       pred.at = 60,
                                                       ngroup = 3)

print(LASSO_Train_CoxPH_Model_ExternalCalibration)

summary(LASSO_Train_CoxPH_Model_ExternalCalibration)

plot(LASSO_Train_CoxPH_Model_ExternalCalibration)

##################################
# Estimating survival curves
# of the LASSO model
# for the risk groups
# using the test data
##################################
LASSO_Test_CoxPH_Model_KMPlot <- kmplot( LASSO_Train_CoxPH_Model_ExternalCalibration,
                                          group.name = c("High-Risk", "Medium-Risk", "Low-Risk"),
                                          time.at = 1:10 * 12)

##################################
# Conducting an external calibration
# of the LASSO model
# using the test data
# for Year 10 (Time = 120)
##################################
LASSO_Train_CoxPH_Model_ExternalCalibration <- calibrate_external(LASSO_Train_CoxPH_Fit,
                                                       LASSO_Train_Predictors,
                                                       LASSO_Train_Time,
                                                       LASSO_Train_Status,
                                                       LASSO_Test_Predictors,
                                                       LASSO_Test_Time,
                                                       LASSO_Test_Status,
                                                       pred.at = 120,
                                                       ngroup = 3)

print(LASSO_Train_CoxPH_Model_ExternalCalibration)

summary(LASSO_Train_CoxPH_Model_ExternalCalibration)

plot(LASSO_Train_CoxPH_Model_ExternalCalibration)

##################################
# Estimating survival curves
# of the LASSO model
# for the risk groups
# using the test data
##################################
LASSO_Test_CoxPH_Model_KMPlot <- kmplot( LASSO_Train_CoxPH_Model_ExternalCalibration,
                                          group.name = c("High-Risk", "Medium-Risk", "Low-Risk"),
                                          time.at = 1:10 * 12)

```

</details>

###  1.5.2 Elastic Net (ENET)
|
| [Elastic Net Regression](https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1467-9868.2005.00503.x) is a regularization technique aimed at balancing between sparsity and including correlated predictors. The algorithm is a combination of the ridge and LASSO regression methods, by adding both L1 and L2 regularization terms in the cost function. The LASSO penalty promotes sparsity by encouraging some coefficients to be exactly zero, while the ridge penalty encourages shrinkage of coefficients towards zero. This method introduces two tuning parameters: lambda, which controls the overall amount of penalty applied, and alpha which determines the trade-off between the LASSO and ridge penalties. The method formulates an optimization problem that minimizes the negative log-partial likelihood of the Cox proportional hazards model subject to the penalty terms. The optimization problem is solved using coordinate descent or proximal gradient methods, by iteratively updating regression coefficients, while considering both the LASSO and ridge penalties. This approach can be useful for striking a balance between sparsity and accounting for correlated predictors by effectively identifying important predictors while handling multicollinearity and improving both the interpretability and predictive performance of the survival model.
|
| **[A]** The multivariate Cox proportional hazards regression model from the  <mark style="background-color: #CCECFF">**survival**</mark> package was implemented with the ENET penalty function applied using the <mark style="background-color: #CCECFF">**hdnom**</mark>, <mark style="background-color: #CCECFF">**penalized**</mark> and <mark style="background-color: #CCECFF">**glmnet**</mark> packages.
|
| **[B]** The method contains 3 hyperparameters:
|      **[B.1]** <span style="color: #FF0000">nfolds</span> = fold numbers of cross-validation fixed at a value = 5
|      **[B.2]** <span style="color: #FF0000">rule</span> = model selection criterion fixed at a setting of optimal lambda such that error is within 1 standard error of the minimum
|      **[B.3]** <span style="color: #FF0000">alphas</span> = elastic net mixing parameter made to vary across a range of values equal to 0.05 to 0.95
|
| **[C]** The method selected 7 out of the 25 predictors for the final Cox Proportional Hazards model as follows:
|      **[C.1]** <span style="color: #FF0000">betablok</span> variable (factor)
|      **[C.2]** <span style="color: #FF0000">resting.hr</span> variable (numeric)
|      **[C.3]** <span style="color: #FF0000">lvef.metabl</span> variable (numeric)
|      **[C.4]** <span style="color: #FF0000">peak.vo2</span> variable (numeric)
|      **[C.5]** <span style="color: #FF0000">interval</span> variable (numeric)
|      **[C.6]** <span style="color: #FF0000">bun</span> variable (numeric)
|      **[C.7]** <span style="color: #FF0000">male</span> variable (factor)
|
| **[D]** Optimal model parameters were determined as:
|      **[D.1]** Lambda = 0.209
|      **[D.2]** Alpha = 0.200
|
| **[E]** Internally validated Time-Dependent AUROC metrics using bootstrap resampling of the train data showed good performance overall except for the last few time periods and are summarized as follows:
|      **[E.1]** 12 months = 0.76568
|      **[E.2]** 24 months = 0.77544
|      **[E.3]** 36 months = 0.66988
|      **[E.4]** 48 months = 0.67471
|      **[E.5]** 60 months = 0.66267
|      **[E.6]** 72 months = 0.67954
|      **[E.7]** 84 months = 0.71874
|      **[E.8]** 96 months = 0.60604
|      **[E.9]** 108 months = 0.66103
|      **[E.10]** 120 months = 0.46548
|
| **[F]** Externally validated Time-Dependent AUROC metrics using the test data showed good performance overall except for the last few time periods and are summarized as follows:
|      **[F.1]** 12 months = 0.77262
|      **[F.2]** 24 months = 0.74574
|      **[F.3]** 36 months = 0.63438
|      **[F.4]** 48 months = 0.61830
|      **[F.5]** 60 months = 0.65565
|      **[F.6]** 72 months = 0.66441
|      **[F.7]** 84 months = 0.62992
|      **[F.8]** 96 months = 0.69808
|      **[F.9]** 108 months = 0.41854
|      **[F.10]** 120 months = 0.35000
|
| **[G]** Model predictions at time = 60 months were reasonably calibrated for both the train and test data. Kaplan-Meier survival curves for the three risk groups from the calibration data were differentially profiled with p-value < 0.05. 
|
| **[H]** Model predictions at time = 120 months were reasonably calibrated for both the train and test data. Kaplan-Meier survival curves for the three risk groups from the calibration data were differentially profiled with p-value < 0.05.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.5.2, warning=FALSE, message=FALSE}
##################################
# Loading the preprocessed data
##################################
PMA_PreModelling_ENET <- peakVO2.Source[,!names(peakVO2.Source) %in% rownames(UF_CoxPHModelSummary_NonSig)]

##################################
# Setting the appropriate variable types
##################################
PMA_PreModelling_ENET$died <- as.factor(PMA_PreModelling_ENET$died)

##################################
# Creating a local object
# for the train and test sets
##################################
set.seed(88888888)
TrainIndex <- createDataPartition(PMA_PreModelling_ENET$died, 
                                  p = 0.8, 
                                  list = FALSE, 
                                  times = 1)

PMA_PreModelling_ENET_Train <- PMA_PreModelling_ENET[ TrainIndex,]
PMA_PreModelling_ENET_Test  <- PMA_PreModelling_ENET[-TrainIndex,]

PMA_PreModelling_ENET_Train$died <- as.numeric(PMA_PreModelling_ENET_Train$died)
PMA_PreModelling_ENET_Test$died  <- as.numeric(PMA_PreModelling_ENET_Test$died)

##################################
# Formulating the model components
# for the train data
##################################
ENET_Train_Predictors <- as.matrix(
  PMA_PreModelling_ENET_Train[,!names(PMA_PreModelling_ENET_Train) 
                               %in% c("ttodead","died")])
ENET_Train_Time    <- PMA_PreModelling_ENET_Train$ttodead
ENET_Train_Status  <- PMA_PreModelling_ENET_Train$died
ENET_Train_Response <- survival::Surv(ENET_Train_Time, ENET_Train_Status)

##################################
# Fitting a ENET model
##################################
ENET_Train_CoxPH_Fit <- fit_enet(ENET_Train_Predictors,
                              ENET_Train_Response,
                              nfolds = 5,
                              alphas = seq(0.05, 0.95, 0.05),
                              rule = "lambda.1se",
                              seed = 88888888)

##################################
# Extracting the model objects and
# optimal hyperparameters
# from the ENET model
##################################
(ENET_Train_CoxPH_Model  <- ENET_Train_CoxPH_Fit$model)
(ENET_Train_CoxPH_Model  <- ENET_Train_CoxPH_Fit$model$beta)
(ENET_Train_CoxPH_Alpha <- ENET_Train_CoxPH_Fit$alpha)
(ENET_Train_CoxPH_Lambda <- ENET_Train_CoxPH_Fit$lambda)

##################################
# Conducting an internal validation
# of the ENET model
# using a 50-cycle bootstrap
##################################
ENET_Train_CoxPH_Model_InternalValidation <- validate(ENET_Train_Predictors,
                                                       ENET_Train_Time,
                                                       ENET_Train_Status,
                                                       model.type = "enet",
                                                       alpha = ENET_Train_CoxPH_Fit$alpha,
                                                       lambda = ENET_Train_CoxPH_Fit$lambda,
                                                       method = "bootstrap",
                                                       boot.times = 50,
                                                       tauc.type = "UNO",
                                                       tauc.time = seq(12, 120, 12),
                                                       seed = 88888888)

print(ENET_Train_CoxPH_Model_InternalValidation)

summary(ENET_Train_CoxPH_Model_InternalValidation)

ENET_Train_IV_Summary <- data.frame(matrix(ncol=4, nrow=10))
names(ENET_Train_IV_Summary) <- c("Model","Validation","MedianTDAUROC","Time")

for (i in 1:10){
  ENET_Train_IV_Summary[i,1] <- "ENET"
  ENET_Train_IV_Summary[i,2] <- "Cross-Validation"
  ENET_Train_IV_Summary[i,3] <- summary(ENET_Train_CoxPH_Model_InternalValidation)[[4,i]]
  ENET_Train_IV_Summary[i,4] <- i*12 
}

ENET_Train_IV_Summary

plot(ENET_Train_CoxPH_Model_InternalValidation,
     ylim = c(0, 1))

##################################
# Conducting an external validation
# of the ENET model
# using the test data
##################################
ENET_Test_Predictors <- as.matrix(
  PMA_PreModelling_ENET_Test[,!names(PMA_PreModelling_ENET_Test)
                               %in% c("ttodead","died")])
ENET_Test_Time    <- PMA_PreModelling_ENET_Test$ttodead
ENET_Test_Status  <- PMA_PreModelling_ENET_Test$died
ENET_Test_Response <- survival::Surv(ENET_Test_Time, ENET_Test_Status)

ENET_Train_CoxPH_Model_ExternalValidation <- validate_external(ENET_Train_CoxPH_Fit,
                                                       ENET_Train_Predictors,
                                                       ENET_Train_Time,
                                                       ENET_Train_Status,
                                                       ENET_Test_Predictors,
                                                       ENET_Test_Time,
                                                       ENET_Test_Status,
                                                       tauc.type = "UNO",
                                                       tauc.time = seq(12, 120, 12))

print(ENET_Train_CoxPH_Model_ExternalValidation)

summary(ENET_Train_CoxPH_Model_ExternalValidation)

ENET_Train_EV_Summary <- data.frame(matrix(ncol=4, nrow=10))
names(ENET_Train_EV_Summary) <- c("Model","Validation","MedianTDAUROC","Time")

for (i in 1:10){
  ENET_Train_EV_Summary[i,1] <- "ENET"
  ENET_Train_EV_Summary[i,2] <- "Test"
  ENET_Train_EV_Summary[i,3] <- summary(ENET_Train_CoxPH_Model_ExternalValidation)[[1,i]]
  ENET_Train_EV_Summary[i,4] <- i*12
}

ENET_Train_EV_Summary

plot(ENET_Train_CoxPH_Model_ExternalValidation,
     ylim = c(0, 1))

##################################
# Conducting an internal calibration
# of the ENET model
# using a 50-cycle bootstrap
# for Year 5 (Time = 60)
##################################
ENET_Train_CoxPH_Model_InternalCalibration <- calibrate(ENET_Train_Predictors,
                                                       ENET_Train_Time,
                                                       ENET_Train_Status,
                                                       model.type = "enet",
                                                       alpha = ENET_Train_CoxPH_Fit$alpha,
                                                       lambda = ENET_Train_CoxPH_Fit$lambda,
                                                       method = "bootstrap",
                                                       boot.times = 50,
                                                       pred.at = 60,
                                                       ngroup = 3,
                                                       seed = 88888888)

print(ENET_Train_CoxPH_Model_InternalCalibration)

summary(ENET_Train_CoxPH_Model_InternalCalibration)

plot(ENET_Train_CoxPH_Model_InternalCalibration)

##################################
# Estimating survival curves
# of the ENET model
# for the risk groups
# using the train data
##################################
ENET_Train_CoxPH_Model_KMPlot <- kmplot( ENET_Train_CoxPH_Model_InternalCalibration,
                                          group.name = c("High-Risk", "Medium-Risk", "Low-Risk"),
                                          time.at = 1:10 * 12)

##################################
# Conducting an internal calibration
# of the ENET model
# using a 50-cycle bootstrap
# for Year 10 (Time = 120)
##################################
ENET_Train_CoxPH_Model_InternalCalibration <- calibrate(ENET_Train_Predictors,
                                                       ENET_Train_Time,
                                                       ENET_Train_Status,
                                                       model.type = "enet",
                                                       alpha = ENET_Train_CoxPH_Fit$alpha,
                                                       lambda = ENET_Train_CoxPH_Fit$lambda,
                                                       method = "bootstrap",
                                                       boot.times = 50,
                                                       pred.at = 120,
                                                       ngroup = 3,
                                                       seed = 88888888)

print(ENET_Train_CoxPH_Model_InternalCalibration)

summary(ENET_Train_CoxPH_Model_InternalCalibration)

plot(ENET_Train_CoxPH_Model_InternalCalibration)

##################################
# Estimating survival curves
# of the ENET model
# for the risk groups
# using the train data
##################################
ENET_Train_CoxPH_Model_KMPlot <- kmplot( ENET_Train_CoxPH_Model_InternalCalibration,
                                          group.name = c("High-Risk", "Medium-Risk", "Low-Risk"),
                                          time.at = 1:10 * 12)

##################################
# Conducting an external calibration
# of the ENET model
# using the test data
# for Year 5 (Time = 60)
##################################
ENET_Train_CoxPH_Model_ExternalCalibration <- calibrate_external(ENET_Train_CoxPH_Fit,
                                                       ENET_Train_Predictors,
                                                       ENET_Train_Time,
                                                       ENET_Train_Status,
                                                       ENET_Test_Predictors,
                                                       ENET_Test_Time,
                                                       ENET_Test_Status,
                                                       pred.at = 60,
                                                       ngroup = 3)

print(ENET_Train_CoxPH_Model_ExternalCalibration)

summary(ENET_Train_CoxPH_Model_ExternalCalibration)

plot(ENET_Train_CoxPH_Model_ExternalCalibration)

##################################
# Estimating survival curves
# of the ENET model
# for the risk groups
# using the test data
##################################
ENET_Test_CoxPH_Model_KMPlot <- kmplot( ENET_Train_CoxPH_Model_ExternalCalibration,
                                          group.name = c("High-Risk", "Medium-Risk", "Low-Risk"),
                                          time.at = 1:10 * 12)

##################################
# Conducting an external calibration
# of the ENET model
# using the test data
# for Year 10 (Time = 120)
##################################
ENET_Train_CoxPH_Model_ExternalCalibration <- calibrate_external(ENET_Train_CoxPH_Fit,
                                                       ENET_Train_Predictors,
                                                       ENET_Train_Time,
                                                       ENET_Train_Status,
                                                       ENET_Test_Predictors,
                                                       ENET_Test_Time,
                                                       ENET_Test_Status,
                                                       pred.at = 120,
                                                       ngroup = 3)

print(ENET_Train_CoxPH_Model_ExternalCalibration)

summary(ENET_Train_CoxPH_Model_ExternalCalibration)

plot(ENET_Train_CoxPH_Model_ExternalCalibration)

##################################
# Estimating survival curves
# of the ENET model
# for the risk groups
# using the test data
##################################
ENET_Test_CoxPH_Model_KMPlot <- kmplot( ENET_Train_CoxPH_Model_ExternalCalibration,
                                          group.name = c("High-Risk", "Medium-Risk", "Low-Risk"),
                                          time.at = 1:10 * 12)

```

</details>

###  1.5.3 Minimax Concave Penalty (MCP)
|
| [Minimax Concave Penalty](https://www.jstor.org/stable/25662264) is a regularization technique aimed at encouraging sparsity in the model by imposing folded concave penalty functions on the regression coefficients. The algorithm uses the tuning parameter lambda which controls the amount of penalty applied, and a shape parameter gamma which determines the concavity of the penalty function. The method formulates an optimization problem that minimizes the negative log-partial likelihood of the Cox proportional hazards model subject to the penalty terms. The optimization problem is solved using coordinate descent, by iteratively updating regression coefficients, while incorporating the MCP penalty. The MCP penalty retains the penalization rate (and bias) of the LASSO for small coefficients, but immedciately relaxes the rate of penalization as the absolute value of the coefficient increases. This approach can be useful for feature selection, allowing for the identification of a parsimonious set of predictors that significantly impact survival outcomes, while balancing the trade-off between model complexity and prediction.
|
| **[A]** The multivariate Cox proportional hazards regression model from the  <mark style="background-color: #CCECFF">**survival**</mark> package was implemented with the MCP penalty function applied using the <mark style="background-color: #CCECFF">**hdnom**</mark>, <mark style="background-color: #CCECFF">**penalized**</mark> and <mark style="background-color: #CCECFF">**ncvreg**</mark> packages.
|
| **[B]** The method contains 2 hyperparameters:
|      **[B.1]** <span style="color: #FF0000">nfolds</span> = fold numbers of cross-validation fixed at a value = 5
|      **[B.2]** <span style="color: #FF0000">gammas</span> = MCP penalty made to vary across a range of values equal to 2.10 to 5.00
|
| **[C]** The method selected 13 out of the 25 predictors for the final Cox Proportional Hazards model as follows:
|      **[C.1]** <span style="color: #FF0000">age</span> variable (numeric)
|      **[C.2]** <span style="color: #FF0000">betablok</span> variable (factor)
|      **[C.3]** <span style="color: #FF0000">acei</span> variable (factor)
|      **[C.4]** <span style="color: #FF0000">aspirin</span> variable (factor)
|      **[C.5]** <span style="color: #FF0000">insulin</span> variable (factor)
|      **[C.6]** <span style="color: #FF0000">resting.systolic.bp</span> variable (numeric)
|      **[C.7]** <span style="color: #FF0000">resting.hr</span> variable (numeric)
|      **[C.8]** <span style="color: #FF0000">lvef.metabl</span> variable (numeric)
|      **[C.9]** <span style="color: #FF0000">peak.vo2</span> variable (numeric)
|      **[C.10]** <span style="color: #FF0000">interval</span> variable (numeric)
|      **[C.11]** <span style="color: #FF0000">cad</span> variable (factor)
|      **[C.12]** <span style="color: #FF0000">bun</span> variable (numeric)
|      **[C.13]** <span style="color: #FF0000">male</span> variable (factor)
|
| **[D]** Optimal model parameters were determined as:
|      **[D.1]** Lambda = 0.014
|      **[D.2]** Gamma = 4.000
|
| **[E]** Internally validated Time-Dependent AUROC metrics using bootstrap resampling of the train data showed good performance overall except for the last few time periods and are summarized as follows:
|      **[E.1]** 12 months = 0.76617
|      **[E.2]** 24 months = 0.77818
|      **[E.3]** 36 months = 0.68530
|      **[E.4]** 48 months = 0.67992
|      **[E.5]** 60 months = 0.66145
|      **[E.6]** 72 months = 0.67633
|      **[E.7]** 84 months = 0.68757
|      **[E.8]** 96 months = 0.61512
|      **[E.9]** 108 months = 0.62571
|      **[E.10]** 120 months = 0.26660
|
| **[F]** Externally validated Time-Dependent AUROC metrics using the test data showed good performance overall except for the last few time periods and are summarized as follows:
|      **[F.1]** 12 months = 0.80360
|      **[F.2]** 24 months = 0.74632
|      **[F.3]** 36 months = 0.64447
|      **[F.4]** 48 months = 0.60192
|      **[F.5]** 60 months = 0.64827
|      **[F.6]** 72 months = 0.60107
|      **[F.7]** 84 months = 0.56609
|      **[F.8]** 96 months = 0.65251
|      **[F.9]** 108 months = 0.46980
|      **[F.10]** 120 months = 0.27500
|
| **[G]** Model predictions at time = 60 months were reasonably calibrated for both the train and test data. Kaplan-Meier survival curves for the three risk groups from the calibration data were differentially profiled with p-value < 0.05. 
|
| **[H]** Model predictions at time = 120 months were reasonably calibrated for both the train and test data. Kaplan-Meier survival curves for the three risk groups from the calibration data were differentially profiled with p-value < 0.05.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.5.3, warning=FALSE, message=FALSE}
##################################
# Loading the preprocessed data
##################################
PMA_PreModelling_MCP <- peakVO2.Source[,!names(peakVO2.Source) %in% rownames(UF_CoxPHModelSummary_NonSig)]

##################################
# Setting the appropriate variable types
##################################
PMA_PreModelling_MCP$died <- as.factor(PMA_PreModelling_MCP$died)

##################################
# Creating a local object
# for the train and test sets
##################################
set.seed(88888888)
TrainIndex <- createDataPartition(PMA_PreModelling_MCP$died, 
                                  p = 0.8, 
                                  list = FALSE, 
                                  times = 1)

PMA_PreModelling_MCP_Train <- PMA_PreModelling_MCP[ TrainIndex,]
PMA_PreModelling_MCP_Test  <- PMA_PreModelling_MCP[-TrainIndex,]

PMA_PreModelling_MCP_Train$died <- as.numeric(PMA_PreModelling_MCP_Train$died)
PMA_PreModelling_MCP_Test$died  <- as.numeric(PMA_PreModelling_MCP_Test$died)

##################################
# Formulating the model components
# for the train data
##################################
MCP_Train_Predictors <- as.matrix(
  PMA_PreModelling_MCP_Train[,!names(PMA_PreModelling_MCP_Train) 
                               %in% c("ttodead","died")])
MCP_Train_Time    <- PMA_PreModelling_MCP_Train$ttodead
MCP_Train_Status  <- PMA_PreModelling_MCP_Train$died
MCP_Train_Response <- survival::Surv(MCP_Train_Time, MCP_Train_Status)

##################################
# Fitting a MCP model
##################################
MCP_Train_CoxPH_Fit <- fit_mcp(MCP_Train_Predictors,
                              MCP_Train_Response,
                              nfolds = 5, 
                              gammas = c(2.1, 3, 4, 5),
                              seed = 88888888,
                              trace = FALSE)

##################################
# Extracting the model objects and
# optimal hyperparameters
# from the MCP model
##################################
(MCP_Train_CoxPH_Model  <- MCP_Train_CoxPH_Fit$model)
(MCP_Train_CoxPH_Model  <- MCP_Train_CoxPH_Fit$model$beta)
(MCP_Train_CoxPH_Lambda <- MCP_Train_CoxPH_Fit$lambda)
(MCP_Train_CoxPH_Gamma <- MCP_Train_CoxPH_Fit$gamma)

##################################
# Conducting an internal validation
# of the MCP model
# using a 50-cycle bootstrap
##################################
MCP_Train_CoxPH_Model_InternalValidation <- validate(MCP_Train_Predictors,
                                                       MCP_Train_Time,
                                                       MCP_Train_Status,
                                                       model.type = "mcp",
                                                       alpha = 1,
                                                       lambda = MCP_Train_CoxPH_Fit$lambda,
                                                       gamma = MCP_Train_CoxPH_Fit$gamma,
                                                       method = "bootstrap",
                                                       boot.times = 50,
                                                       tauc.type = "UNO",
                                                       tauc.time = seq(12, 120, 12),
                                                       seed = 88888888)

print(MCP_Train_CoxPH_Model_InternalValidation)

summary(MCP_Train_CoxPH_Model_InternalValidation)

MCP_Train_IV_Summary <- data.frame(matrix(ncol=4, nrow=10))
names(MCP_Train_IV_Summary) <- c("Model","Validation","MedianTDAUROC","Time")

for (i in 1:10){
  MCP_Train_IV_Summary[i,1] <- "MCP"
  MCP_Train_IV_Summary[i,2] <- "Cross-Validation"
  MCP_Train_IV_Summary[i,3] <- summary(MCP_Train_CoxPH_Model_InternalValidation)[[4,i]]
  MCP_Train_IV_Summary[i,4] <- i*12
}

MCP_Train_IV_Summary

plot(MCP_Train_CoxPH_Model_InternalValidation,
     ylim = c(0, 1))

##################################
# Conducting an external validation
# of the MCP model
# using the test data
##################################
MCP_Test_Predictors <- as.matrix(
  PMA_PreModelling_MCP_Test[,!names(PMA_PreModelling_MCP_Test)
                               %in% c("ttodead","died")])
MCP_Test_Time    <- PMA_PreModelling_MCP_Test$ttodead
MCP_Test_Status  <- PMA_PreModelling_MCP_Test$died
MCP_Test_Response <- survival::Surv(MCP_Test_Time, MCP_Test_Status)

MCP_Train_CoxPH_Model_ExternalValidation <- validate_external(MCP_Train_CoxPH_Fit,
                                                       MCP_Train_Predictors,
                                                       MCP_Train_Time,
                                                       MCP_Train_Status,
                                                       MCP_Test_Predictors,
                                                       MCP_Test_Time,
                                                       MCP_Test_Status,
                                                       tauc.type = "UNO",
                                                       tauc.time = seq(12, 120, 12))

print(MCP_Train_CoxPH_Model_ExternalValidation)

summary(MCP_Train_CoxPH_Model_ExternalValidation)

MCP_Train_EV_Summary <- data.frame(matrix(ncol=4, nrow=10))
names(MCP_Train_EV_Summary) <- c("Model","Validation","MedianTDAUROC","Time")

for (i in 1:10){
  MCP_Train_EV_Summary[i,1] <- "MCP"
  MCP_Train_EV_Summary[i,2] <- "Test"
  MCP_Train_EV_Summary[i,3] <- summary(MCP_Train_CoxPH_Model_ExternalValidation)[[1,i]]
  MCP_Train_EV_Summary[i,4] <- i*12
}

MCP_Train_EV_Summary

plot(MCP_Train_CoxPH_Model_ExternalValidation,
     ylim = c(0, 1))

##################################
# Conducting an internal calibration
# of the MCP model
# using a 50-cycle bootstrap
# for Year 5 (Time = 60)
##################################
MCP_Train_CoxPH_Model_InternalCalibration <- calibrate(MCP_Train_Predictors,
                                                       MCP_Train_Time,
                                                       MCP_Train_Status,
                                                       model.type = "mcp",
                                                       alpha = 1,
                                                       lambda = MCP_Train_CoxPH_Fit$lambda,
                                                       gamma = MCP_Train_CoxPH_Fit$gamma,
                                                       method = "bootstrap",
                                                       boot.times = 50,
                                                       pred.at = 60,
                                                       ngroup = 3,
                                                       seed = 88888888)

print(MCP_Train_CoxPH_Model_InternalCalibration)

summary(MCP_Train_CoxPH_Model_InternalCalibration)

plot(MCP_Train_CoxPH_Model_InternalCalibration)

##################################
# Estimating survival curves
# of the MCP model
# for the risk groups
# using the train data
##################################
MCP_Train_CoxPH_Model_KMPlot <- kmplot( MCP_Train_CoxPH_Model_InternalCalibration,
                                          group.name = c("High-Risk", "Medium-Risk", "Low-Risk"),
                                          time.at = 1:10 * 12)

##################################
# Conducting an internal calibration
# of the MCP model
# using a 50-cycle bootstrap
# for Year 10 (Time = 120)
##################################
MCP_Train_CoxPH_Model_InternalCalibration <- calibrate(MCP_Train_Predictors,
                                                       MCP_Train_Time,
                                                       MCP_Train_Status,
                                                       model.type = "mcp",
                                                       alpha = 1,
                                                       lambda = MCP_Train_CoxPH_Fit$lambda,
                                                       gamma = MCP_Train_CoxPH_Fit$gamma,
                                                       method = "bootstrap",
                                                       boot.times = 50,
                                                       pred.at = 120,
                                                       ngroup = 3,
                                                       seed = 88888888)

print(MCP_Train_CoxPH_Model_InternalCalibration)

summary(MCP_Train_CoxPH_Model_InternalCalibration)

plot(MCP_Train_CoxPH_Model_InternalCalibration)

##################################
# Estimating survival curves
# of the MCP model
# for the risk groups
# using the train data
##################################
MCP_Train_CoxPH_Model_KMPlot <- kmplot( MCP_Train_CoxPH_Model_InternalCalibration,
                                          group.name = c("High-Risk", "Medium-Risk", "Low-Risk"),
                                          time.at = 1:10 * 12)

##################################
# Conducting an external calibration
# of the MCP model
# using the test data
# for Year 5 (Time = 60)
##################################
MCP_Train_CoxPH_Model_ExternalCalibration <- calibrate_external(MCP_Train_CoxPH_Fit,
                                                       MCP_Train_Predictors,
                                                       MCP_Train_Time,
                                                       MCP_Train_Status,
                                                       MCP_Test_Predictors,
                                                       MCP_Test_Time,
                                                       MCP_Test_Status,
                                                       pred.at = 60,
                                                       ngroup = 3)

print(MCP_Train_CoxPH_Model_ExternalCalibration)

summary(MCP_Train_CoxPH_Model_ExternalCalibration)

plot(MCP_Train_CoxPH_Model_ExternalCalibration)

##################################
# Estimating survival curves
# of the MCP model
# for the risk groups
# using the test data
##################################
MCP_Test_CoxPH_Model_KMPlot <- kmplot( MCP_Train_CoxPH_Model_ExternalCalibration,
                                          group.name = c("High-Risk", "Medium-Risk", "Low-Risk"),
                                          time.at = 1:10 * 12)

##################################
# Conducting an external calibration
# of the MCP model
# using the test data
# for Year 10 (Time = 120)
##################################
MCP_Train_CoxPH_Model_ExternalCalibration <- calibrate_external(MCP_Train_CoxPH_Fit,
                                                       MCP_Train_Predictors,
                                                       MCP_Train_Time,
                                                       MCP_Train_Status,
                                                       MCP_Test_Predictors,
                                                       MCP_Test_Time,
                                                       MCP_Test_Status,
                                                       pred.at = 120,
                                                       ngroup = 3)

print(MCP_Train_CoxPH_Model_ExternalCalibration)

summary(MCP_Train_CoxPH_Model_ExternalCalibration)

plot(MCP_Train_CoxPH_Model_ExternalCalibration)

##################################
# Estimating survival curves
# of the MCP model
# for the risk groups
# using the test data
##################################
MCP_Test_CoxPH_Model_KMPlot <- kmplot( MCP_Train_CoxPH_Model_ExternalCalibration,
                                          group.name = c("High-Risk", "Medium-Risk", "Low-Risk"),
                                          time.at = 1:10 * 12)

```

</details>

###  1.5.4 Smoothly Clipped Absolute Deviation (SCAD)
|
| [Smoothly Clipped Absolute Deviation](https://www.tandfonline.com/doi/abs/10.1198/016214501753382273) is a regularization technique aimed at encouraging sparsity in the model by imposing folded concave penalty functions on the regression coefficients. The algorithm uses the tuning parameter lambda which controls the amount of penalty applied, and a shape parameter gamma which determines the concavity of the penalty function. The method formulates an optimization problem that minimizes the negative log-partial likelihood of the Cox proportional hazards model subject to the penalty terms. The optimization problem is solved using coordinate descent, by iteratively updating regression coefficients, while incorporating the SCAD penalty. The SCAD penalty retains the penalization rate (and bias) of the LASSO for small coefficients, but continuously relaxes the rate of penalization by remaining flat for a while before decreasing as the absolute value of the coefficient increases. This approach can be useful for feature selection, allowing for the identification of a parsimonious set of predictors that significantly impact survival outcomes, while balancing the trade-off between model complexity and prediction.
|
| **[A]** The multivariate Cox proportional hazards regression model from the  <mark style="background-color: #CCECFF">**survival**</mark> package was implemented with the SCAD penalty function applied using the <mark style="background-color: #CCECFF">**hdnom**</mark>, <mark style="background-color: #CCECFF">**penalized**</mark> and <mark style="background-color: #CCECFF">**ncvreg**</mark> packages.
|
| **[B]** The method contains 2 hyperparameters:
|      **[B.1]** <span style="color: #FF0000">nfolds</span> = fold numbers of cross-validation fixed at a value = 5
|      **[B.2]** <span style="color: #FF0000">gammas</span> = MCP penalty made to vary across a range of values equal to 2.10 to 5.00
|
| **[C]** The method selected 15 out of the 25 predictors for the final Cox Proportional Hazards model as follows:
|      **[C.1]** <span style="color: #FF0000">age</span> variable (numeric)
|      **[C.2]** <span style="color: #FF0000">betablok</span> variable (factor)
|      **[C.3]** <span style="color: #FF0000">acei</span> variable (factor)
|      **[C.4]** <span style="color: #FF0000">aspirin</span> variable (factor)
|      **[C.5]** <span style="color: #FF0000">diuretic.thiazide</span> variable (factor)
|      **[C.6]** <span style="color: #FF0000">insulin</span> variable (factor)
|      **[C.7]** <span style="color: #FF0000">resting.systolic.bp</span> variable (numeric)
|      **[C.8]** <span style="color: #FF0000">resting.hr</span> variable (numeric)
|      **[C.9]** <span style="color: #FF0000">lvef.metabl</span> variable (numeric)
|      **[C.10]** <span style="color: #FF0000">peak.vo2</span> variable (numeric)
|      **[C.11]** <span style="color: #FF0000">interval</span> variable (numeric)
|      **[C.12]** <span style="color: #FF0000">cad</span> variable (factor)
|      **[C.13]** <span style="color: #FF0000">bun</span> variable (numeric)
|      **[C.14]** <span style="color: #FF0000">sodium</span> variable (numeric)
|      **[C.15]** <span style="color: #FF0000">male</span> variable (factor)
|
| **[D]** Optimal model parameters were determined as:
|      **[D.1]** Lambda = 0.011
|      **[D.2]** Gamma = 5.000
|
| **[E]** Internally validated Time-Dependent AUROC metrics using bootstrap resampling of the train data showed good performance overall except for the last few time periods and are summarized as follows:
|      **[E.1]** 12 months = 0.76617
|      **[E.2]** 24 months = 0.77818
|      **[E.3]** 36 months = 0.68530
|      **[E.4]** 48 months = 0.67992
|      **[E.5]** 60 months = 0.66145
|      **[E.6]** 72 months = 0.67633
|      **[E.7]** 84 months = 0.68757
|      **[E.8]** 96 months = 0.61512
|      **[E.9]** 108 months = 0.62571
|      **[E.10]** 120 months = 0.26660
|
| **[F]** Externally validated Time-Dependent AUROC metrics using the test data showed good performance overall except for the last few time periods and are summarized as follows:
|      **[F.1]** 12 months = 0.80297
|      **[F.2]** 24 months = 0.74514
|      **[F.3]** 36 months = 0.64428
|      **[F.4]** 48 months = 0.60077
|      **[F.5]** 60 months = 0.64891
|      **[F.6]** 72 months = 0.60476
|      **[F.7]** 84 months = 0.56636
|      **[F.8]** 96 months = 0.65165
|      **[F.9]** 108 months = 0.45666
|      **[F.10]** 120 months = 0.27500
|
| **[G]** Model predictions at time = 60 months were reasonably calibrated for both the train and test data. Kaplan-Meier survival curves for the three risk groups from the calibration data were differentially profiled with p-value < 0.05. 
|
| **[H]** Model predictions at time = 120 months were reasonably calibrated for both the train and test data. Kaplan-Meier survival curves for the three risk groups from the calibration data were differentially profiled with p-value < 0.05.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.5.4, warning=FALSE, message=FALSE}
##################################
# Loading the preprocessed data
##################################
PMA_PreModelling_SCAD <- peakVO2.Source[,!names(peakVO2.Source) %in% rownames(UF_CoxPHModelSummary_NonSig)]

##################################
# Setting the appropriate variable types
##################################
PMA_PreModelling_SCAD$died <- as.factor(PMA_PreModelling_SCAD$died)

##################################
# Creating a local object
# for the train and test sets
##################################
set.seed(88888888)
TrainIndex <- createDataPartition(PMA_PreModelling_SCAD$died, 
                                  p = 0.8, 
                                  list = FALSE, 
                                  times = 1)

PMA_PreModelling_SCAD_Train <- PMA_PreModelling_SCAD[ TrainIndex,]
PMA_PreModelling_SCAD_Test  <- PMA_PreModelling_SCAD[-TrainIndex,]

PMA_PreModelling_SCAD_Train$died <- as.numeric(PMA_PreModelling_SCAD_Train$died)
PMA_PreModelling_SCAD_Test$died  <- as.numeric(PMA_PreModelling_SCAD_Test$died)

##################################
# Formulating the model components
# for the train data
##################################
SCAD_Train_Predictors <- as.matrix(
  PMA_PreModelling_SCAD_Train[,!names(PMA_PreModelling_SCAD_Train) 
                               %in% c("ttodead","died")])
SCAD_Train_Time    <- PMA_PreModelling_SCAD_Train$ttodead
SCAD_Train_Status  <- PMA_PreModelling_SCAD_Train$died
SCAD_Train_Response <- survival::Surv(SCAD_Train_Time, SCAD_Train_Status)

##################################
# Fitting a SCAD model
##################################
SCAD_Train_CoxPH_Fit <- fit_scad(SCAD_Train_Predictors,
                              SCAD_Train_Response,
                              nfolds = 5, 
                              gammas = c(2.1, 3, 4, 5),
                              seed = 88888888,
                              trace = FALSE)

##################################
# Extracting the model objects and
# optimal hyperparameters
# from the SCAD model
##################################
(SCAD_Train_CoxPH_Model  <- SCAD_Train_CoxPH_Fit$model)
(SCAD_Train_CoxPH_Model  <- SCAD_Train_CoxPH_Fit$model$beta)
(SCAD_Train_CoxPH_Lambda <- SCAD_Train_CoxPH_Fit$lambda)
(SCAD_Train_CoxPH_Gamma <- SCAD_Train_CoxPH_Fit$gamma)

##################################
# Conducting an internal validation
# of the SCAD model
# using a 50-cycle bootstrap
##################################
SCAD_Train_CoxPH_Model_InternalValidation <- validate(SCAD_Train_Predictors,
                                                       SCAD_Train_Time,
                                                       SCAD_Train_Status,
                                                       model.type = "scad",
                                                       alpha = 1,
                                                       lambda = SCAD_Train_CoxPH_Fit$lambda,
                                                       gamma = SCAD_Train_CoxPH_Fit$gamma,
                                                       method = "bootstrap",
                                                       boot.times = 50,
                                                       tauc.type = "UNO",
                                                       tauc.time = seq(12, 120, 12),
                                                       seed = 88888888)

print(SCAD_Train_CoxPH_Model_InternalValidation)

summary(SCAD_Train_CoxPH_Model_InternalValidation)

SCAD_Train_IV_Summary <- data.frame(matrix(ncol=4, nrow=10))
names(SCAD_Train_IV_Summary) <- c("Model","Validation","MedianTDAUROC","Time")

for (i in 1:10){
  SCAD_Train_IV_Summary[i,1] <- "SCAD"
  SCAD_Train_IV_Summary[i,2] <- "Cross-Validation"
  SCAD_Train_IV_Summary[i,3] <- summary(SCAD_Train_CoxPH_Model_InternalValidation)[[4,i]]
  SCAD_Train_IV_Summary[i,4] <- i*12
}

SCAD_Train_IV_Summary

plot(SCAD_Train_CoxPH_Model_InternalValidation,
     ylim = c(0, 1))

##################################
# Conducting an external validation
# of the SCAD model
# using the test data
##################################
SCAD_Test_Predictors <- as.matrix(
  PMA_PreModelling_SCAD_Test[,!names(PMA_PreModelling_SCAD_Test)
                               %in% c("ttodead","died")])
SCAD_Test_Time    <- PMA_PreModelling_SCAD_Test$ttodead
SCAD_Test_Status  <- PMA_PreModelling_SCAD_Test$died
SCAD_Test_Response <- survival::Surv(SCAD_Test_Time, SCAD_Test_Status)

SCAD_Train_CoxPH_Model_ExternalValidation <- validate_external(SCAD_Train_CoxPH_Fit,
                                                       SCAD_Train_Predictors,
                                                       SCAD_Train_Time,
                                                       SCAD_Train_Status,
                                                       SCAD_Test_Predictors,
                                                       SCAD_Test_Time,
                                                       SCAD_Test_Status,
                                                       tauc.type = "UNO",
                                                       tauc.time = seq(12, 120, 12))

print(SCAD_Train_CoxPH_Model_ExternalValidation)

summary(SCAD_Train_CoxPH_Model_ExternalValidation)

SCAD_Train_EV_Summary <- data.frame(matrix(ncol=4, nrow=10))
names(SCAD_Train_EV_Summary) <- c("Model","Validation","MedianTDAUROC","Time")

for (i in 1:10){
  SCAD_Train_EV_Summary[i,1] <- "SCAD"
  SCAD_Train_EV_Summary[i,2] <- "Test"
  SCAD_Train_EV_Summary[i,3] <- summary(SCAD_Train_CoxPH_Model_ExternalValidation)[[1,i]]
  SCAD_Train_EV_Summary[i,4] <- i*12
}

SCAD_Train_EV_Summary

plot(SCAD_Train_CoxPH_Model_ExternalValidation,
     ylim = c(0, 1))

##################################
# Conducting an internal calibration
# of the SCAD model
# using a 50-cycle bootstrap
# for Year 5 (Time = 60)
##################################
SCAD_Train_CoxPH_Model_InternalCalibration <- calibrate(SCAD_Train_Predictors,
                                                       SCAD_Train_Time,
                                                       SCAD_Train_Status,
                                                       model.type = "scad",
                                                       alpha = 1,
                                                       lambda = SCAD_Train_CoxPH_Fit$lambda,
                                                       gamma = SCAD_Train_CoxPH_Fit$gamma,
                                                       method = "bootstrap",
                                                       boot.times = 50,
                                                       pred.at = 60,
                                                       ngroup = 3,
                                                       seed = 88888888)

print(SCAD_Train_CoxPH_Model_InternalCalibration)

summary(SCAD_Train_CoxPH_Model_InternalCalibration)

plot(SCAD_Train_CoxPH_Model_InternalCalibration)

##################################
# Estimating survival curves
# of the SCAD model
# for the risk groups
# using the train data
##################################
SCAD_Train_CoxPH_Model_KMPlot <- kmplot( SCAD_Train_CoxPH_Model_InternalCalibration,
                                          group.name = c("High-Risk", "Medium-Risk", "Low-Risk"),
                                          time.at = 1:10 * 12)

##################################
# Conducting an internal calibration
# of the SCAD model
# using a 50-cycle bootstrap
# for Year 10 (Time = 120)
##################################
SCAD_Train_CoxPH_Model_InternalCalibration <- calibrate(SCAD_Train_Predictors,
                                                       SCAD_Train_Time,
                                                       SCAD_Train_Status,
                                                       model.type = "scad",
                                                       alpha = 1,
                                                       lambda = SCAD_Train_CoxPH_Fit$lambda,
                                                       gamma = SCAD_Train_CoxPH_Fit$gamma,
                                                       method = "bootstrap",
                                                       boot.times = 50,
                                                       pred.at = 120,
                                                       ngroup = 3,
                                                       seed = 88888888)

print(SCAD_Train_CoxPH_Model_InternalCalibration)

summary(SCAD_Train_CoxPH_Model_InternalCalibration)

plot(SCAD_Train_CoxPH_Model_InternalCalibration)

##################################
# Estimating survival curves
# of the SCAD model
# for the risk groups
# using the train data
##################################
SCAD_Train_CoxPH_Model_KMPlot <- kmplot( SCAD_Train_CoxPH_Model_InternalCalibration,
                                          group.name = c("High-Risk", "Medium-Risk", "Low-Risk"),
                                          time.at = 1:10 * 12)

##################################
# Conducting an external calibration
# of the SCAD model
# using the test data
# for Year 5 (Time = 60)
##################################
SCAD_Train_CoxPH_Model_ExternalCalibration <- calibrate_external(SCAD_Train_CoxPH_Fit,
                                                       SCAD_Train_Predictors,
                                                       SCAD_Train_Time,
                                                       SCAD_Train_Status,
                                                       SCAD_Test_Predictors,
                                                       SCAD_Test_Time,
                                                       SCAD_Test_Status,
                                                       pred.at = 60,
                                                       ngroup = 3)

print(SCAD_Train_CoxPH_Model_ExternalCalibration)

summary(SCAD_Train_CoxPH_Model_ExternalCalibration)

plot(SCAD_Train_CoxPH_Model_ExternalCalibration)

##################################
# Estimating survival curves
# of the SCAD model
# for the risk groups
# using the test data
##################################
SCAD_Test_CoxPH_Model_KMPlot <- kmplot( SCAD_Train_CoxPH_Model_ExternalCalibration,
                                          group.name = c("High-Risk", "Medium-Risk", "Low-Risk"),
                                          time.at = 1:10 * 12)

##################################
# Conducting an external calibration
# of the SCAD model
# using the test data
# for Year 10 (Time = 120)
##################################
SCAD_Train_CoxPH_Model_ExternalCalibration <- calibrate_external(SCAD_Train_CoxPH_Fit,
                                                       SCAD_Train_Predictors,
                                                       SCAD_Train_Time,
                                                       SCAD_Train_Status,
                                                       SCAD_Test_Predictors,
                                                       SCAD_Test_Time,
                                                       SCAD_Test_Status,
                                                       pred.at = 120,
                                                       ngroup = 3)

print(SCAD_Train_CoxPH_Model_ExternalCalibration)

summary(SCAD_Train_CoxPH_Model_ExternalCalibration)

plot(SCAD_Train_CoxPH_Model_ExternalCalibration)

##################################
# Estimating survival curves
# of the SCAD model
# for the risk groups
# using the test data
##################################
SCAD_Test_CoxPH_Model_KMPlot <- kmplot( SCAD_Train_CoxPH_Model_ExternalCalibration,
                                          group.name = c("High-Risk", "Medium-Risk", "Low-Risk"),
                                          time.at = 1:10 * 12)

```

</details>

###  1.5.5 Fused Least Absolute Shrinkage and Selection Operator (FLASSO)
|
| [Fused Least Absolute Shrinkage and Selection Operator](https://www.jstor.org/stable/3647602) is a regularization technique which extends the LASSO method by incorporating the concept of fused penalties, which encourages grouping or clustering of related variables. The method is aimed at identifying a subset of predictors that have a significant impact on survival outcomes while considering their interdependencies. The penalty term in the fused LASSO method consists of two components - the LASSO penalty and the fused penalty. The LASSO penalty promotes sparsity in the coefficients, forcing some coefficients to be zero. The fused penalty promotes grouping or clustering of related variables by penalizing the differences between neighboring coefficients. This enables the neighboring variables to be either all included or all excluded from the model. The tuning parameters lambda controls the amount of penalty applied. The method formulates an optimization problem that minimizes the negative log-partial likelihood of the Cox proportional hazards model subject to the penalty terms. The optimization problem is solved using coordinate descent, by iteratively updating regression coefficients, taking into account both the LASSO and fused penalties.
|
| **[A]** The multivariate Cox proportional hazards regression model from the  <mark style="background-color: #CCECFF">**survival**</mark> package was implemented with the FLASSO penalty function applied using the <mark style="background-color: #CCECFF">**hdnom**</mark> and <mark style="background-color: #CCECFF">**penalized**</mark> packages.
|
| **[B]** The method contains 3 hyperparameters:
|      **[B.1]** <span style="color: #FF0000">nfolds</span> = fold numbers of cross-validation fixed at a value = 5
|      **[B.2]** <span style="color: #FF0000">lambda1</span> = LASSO penalty made to vary across a range of values equal to 0.001 to 5.000
|      **[B.3]** <span style="color: #FF0000">lambda2</span> = fused LASSO penalty made to vary across a range of values equal to 0.001 to 0.500
|
| **[C]** The method selected 3 out of the 25 predictors for the final Cox Proportional Hazards model. No information about the selected predictors are available.
|
| **[D]** Optimal model parameters were determined as:
|      **[D.1]** Lambda1 = 5.000
|      **[D.2]** Lambda2 = 0.001
|
| **[E]** Internally validated Time-Dependent AUROC metrics using bootstrap resampling of the train data showed good performance overall except for the last few time periods and are summarized as follows:
|      **[E.1]** 12 months = 0.72181
|      **[E.2]** 24 months = 0.71095
|      **[E.3]** 36 months = 0.62796
|      **[E.4]** 48 months = 0.65079
|      **[E.5]** 60 months = 0.63001
|      **[E.6]** 72 months = 0.65456
|      **[E.7]** 84 months = 0.71094
|      **[E.8]** 96 months = 0.57652
|      **[E.9]** 108 months = 0.76628
|      **[E.10]** 120 months = 0.79072
|
| **[F]** Externally validated Time-Dependent AUROC metrics using the test data showed good performance overall except for the last few time periods and are summarized as follows:
|      **[F.1]** 12 months = 0.73644
|      **[F.2]** 24 months = 0.70272
|      **[F.3]** 36 months = 0.58654
|      **[F.4]** 48 months = 0.61131
|      **[F.5]** 60 months = 0.59972
|      **[F.6]** 72 months = 0.63533
|      **[F.7]** 84 months = 0.68976
|      **[F.8]** 96 months = 0.86677
|      **[F.9]** 108 months = 0.46055
|      **[F.10]** 120 months = 0.62500
|
| **[G]** Model predictions at time = 60 months were reasonably calibrated for both the train and test data. Kaplan-Meier survival curves for the three risk groups from the calibration data were differentially profiled with p-value < 0.05. 
|
| **[H]** Model predictions at time = 120 months were reasonably calibrated for both the train and test data. Kaplan-Meier survival curves for the three risk groups from the calibration data were differentially profiled with p-value < 0.05.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.5.5, warning=FALSE, message=FALSE}
##################################
# Loading the preprocessed data
##################################
PMA_PreModelling_FLASSO <- peakVO2.Source[,!names(peakVO2.Source) %in% rownames(UF_CoxPHModelSummary_NonSig)]

##################################
# Setting the appropriate variable types
##################################
PMA_PreModelling_FLASSO$died <- as.factor(PMA_PreModelling_FLASSO$died)

##################################
# Creating a local object
# for the train and test sets
##################################
set.seed(88888888)
TrainIndex <- createDataPartition(PMA_PreModelling_FLASSO$died, 
                                  p = 0.8, 
                                  list = FALSE, 
                                  times = 1)

PMA_PreModelling_FLASSO_Train <- PMA_PreModelling_FLASSO[ TrainIndex,]
PMA_PreModelling_FLASSO_Test  <- PMA_PreModelling_FLASSO[-TrainIndex,]

PMA_PreModelling_FLASSO_Train$died <- as.numeric(PMA_PreModelling_FLASSO_Train$died)
PMA_PreModelling_FLASSO_Test$died  <- as.numeric(PMA_PreModelling_FLASSO_Test$died)

##################################
# Formulating the model components
# for the train data
##################################
FLASSO_Train_Predictors <- as.matrix(
  PMA_PreModelling_FLASSO_Train[,!names(PMA_PreModelling_FLASSO_Train) 
                               %in% c("ttodead","died")])
FLASSO_Train_Time    <- PMA_PreModelling_FLASSO_Train$ttodead
FLASSO_Train_Status  <- PMA_PreModelling_FLASSO_Train$died
FLASSO_Train_Response <- survival::Surv(FLASSO_Train_Time, FLASSO_Train_Status)

##################################
# Fitting a FLASSO model
##################################
FLASSO_Train_CoxPH_Fit <- fit_flasso(FLASSO_Train_Predictors,
                              FLASSO_Train_Response,
                              nfolds = 5, 
                              lambda1 = c(0.001, 0.05, 0.5, 1, 5),
                              lambda2 = c(0.001, 0.01, 0.5),
                              seed = 88888888,
                              trace = FALSE)

##################################
# Extracting the model objects and
# optimal hyperparameters
# from the FLASSO model
##################################
(FLASSO_Train_CoxPH_Model  <- FLASSO_Train_CoxPH_Fit$model)
(FLASSO_Train_CoxPH_Lambda1 <- FLASSO_Train_CoxPH_Fit$lambda1)
(FLASSO_Train_CoxPH_Lambda2 <- FLASSO_Train_CoxPH_Fit$lambda2)

##################################
# Conducting an internal validation
# of the FLASSO model
# using a 50-cycle bootstrap
##################################
FLASSO_Train_CoxPH_Model_InternalValidation <- validate(FLASSO_Train_Predictors,
                                                       FLASSO_Train_Time,
                                                       FLASSO_Train_Status,
                                                       model.type = "flasso",
                                                       lambda1 = FLASSO_Train_CoxPH_Fit$lambda1,
                                                       lambda2 = FLASSO_Train_CoxPH_Fit$lambda2,
                                                       method = "bootstrap",
                                                       boot.times = 50,
                                                       tauc.type = "UNO",
                                                       tauc.time = seq(12, 120, 12),
                                                       seed = 88888888)

print(FLASSO_Train_CoxPH_Model_InternalValidation)

summary(FLASSO_Train_CoxPH_Model_InternalValidation)

FLASSO_Train_IV_Summary <- data.frame(matrix(ncol=4, nrow=10))
names(FLASSO_Train_IV_Summary) <- c("Model","Validation","MedianTDAUROC","Time")

for (i in 1:10){
  FLASSO_Train_IV_Summary[i,1] <- "FLASSO"
  FLASSO_Train_IV_Summary[i,2] <- "Cross-Validation"
  FLASSO_Train_IV_Summary[i,3] <- summary(FLASSO_Train_CoxPH_Model_InternalValidation)[[4,i]]
  FLASSO_Train_IV_Summary[i,4] <- i*12
}

FLASSO_Train_IV_Summary

plot(FLASSO_Train_CoxPH_Model_InternalValidation,
     ylim = c(0, 1))

##################################
# Conducting an external validation
# of the FLASSO model
# using the test data
##################################
FLASSO_Test_Predictors <- as.matrix(
  PMA_PreModelling_FLASSO_Test[,!names(PMA_PreModelling_FLASSO_Test)
                               %in% c("ttodead","died")])
FLASSO_Test_Time    <- PMA_PreModelling_FLASSO_Test$ttodead
FLASSO_Test_Status  <- PMA_PreModelling_FLASSO_Test$died
FLASSO_Test_Response <- survival::Surv(FLASSO_Test_Time, FLASSO_Test_Status)

FLASSO_Train_CoxPH_Model_ExternalValidation <- validate_external(FLASSO_Train_CoxPH_Fit,
                                                       FLASSO_Train_Predictors,
                                                       FLASSO_Train_Time,
                                                       FLASSO_Train_Status,
                                                       FLASSO_Test_Predictors,
                                                       FLASSO_Test_Time,
                                                       FLASSO_Test_Status,
                                                       tauc.type = "UNO",
                                                       tauc.time = seq(12, 120, 12))

print(FLASSO_Train_CoxPH_Model_ExternalValidation)

summary(FLASSO_Train_CoxPH_Model_ExternalValidation)

FLASSO_Train_EV_Summary <- data.frame(matrix(ncol=4, nrow=10))
names(FLASSO_Train_EV_Summary) <- c("Model","Validation","MedianTDAUROC","Time")

for (i in 1:10){
  FLASSO_Train_EV_Summary[i,1] <- "FLASSO"
  FLASSO_Train_EV_Summary[i,2] <- "Test"
  FLASSO_Train_EV_Summary[i,3] <- summary(FLASSO_Train_CoxPH_Model_ExternalValidation)[[1,i]]
  FLASSO_Train_EV_Summary[i,4] <- i*12
}

FLASSO_Train_EV_Summary

plot(FLASSO_Train_CoxPH_Model_ExternalValidation,
     ylim = c(0, 1))

##################################
# Conducting an internal calibration
# of the FLASSO model
# using a 50-cycle bootstrap
# for Year 5 (Time = 60)
##################################
FLASSO_Train_CoxPH_Model_InternalCalibration <- calibrate(FLASSO_Train_Predictors,
                                                       FLASSO_Train_Time,
                                                       FLASSO_Train_Status,
                                                       model.type = "flasso",
                                                       lambda1 = FLASSO_Train_CoxPH_Fit$lambda1,
                                                       lambda2 = FLASSO_Train_CoxPH_Fit$lambda2,
                                                       method = "bootstrap",
                                                       boot.times = 50,
                                                       pred.at = 60,
                                                       ngroup = 3,
                                                       seed = 88888888)

print(FLASSO_Train_CoxPH_Model_InternalCalibration)

summary(FLASSO_Train_CoxPH_Model_InternalCalibration)

plot(FLASSO_Train_CoxPH_Model_InternalCalibration)

##################################
# Estimating survival curves
# of the FLASSO model
# for the risk groups
# using the train data
##################################
FLASSO_Train_CoxPH_Model_KMPlot <- kmplot( FLASSO_Train_CoxPH_Model_InternalCalibration,
                                          group.name = c("High-Risk", "Medium-Risk", "Low-Risk"),
                                          time.at = 1:10 * 12)

##################################
# Conducting an internal calibration
# of the FLASSO model
# using a 50-cycle bootstrap
# for Year 10 (Time = 120)
##################################
FLASSO_Train_CoxPH_Model_InternalCalibration <- calibrate(FLASSO_Train_Predictors,
                                                       FLASSO_Train_Time,
                                                       FLASSO_Train_Status,
                                                       model.type = "flasso",
                                                       lambda1 = FLASSO_Train_CoxPH_Fit$lambda1,
                                                       lambda2 = FLASSO_Train_CoxPH_Fit$lambda2,
                                                       method = "bootstrap",
                                                       boot.times = 50,
                                                       pred.at = 120,
                                                       ngroup = 3,
                                                       seed = 88888888)

print(FLASSO_Train_CoxPH_Model_InternalCalibration)

summary(FLASSO_Train_CoxPH_Model_InternalCalibration)

plot(FLASSO_Train_CoxPH_Model_InternalCalibration)

##################################
# Estimating survival curves
# of the FLASSO model
# for the risk groups
# using the train data
##################################
FLASSO_Train_CoxPH_Model_KMPlot <- kmplot( FLASSO_Train_CoxPH_Model_InternalCalibration,
                                          group.name = c("High-Risk", "Medium-Risk", "Low-Risk"),
                                          time.at = 1:10 * 12)

##################################
# Conducting an external calibration
# of the FLASSO model
# using the test data
# for Year 5 (Time = 60)
##################################
FLASSO_Train_CoxPH_Model_ExternalCalibration <- calibrate_external(FLASSO_Train_CoxPH_Fit,
                                                       FLASSO_Train_Predictors,
                                                       FLASSO_Train_Time,
                                                       FLASSO_Train_Status,
                                                       FLASSO_Test_Predictors,
                                                       FLASSO_Test_Time,
                                                       FLASSO_Test_Status,
                                                       pred.at = 60,
                                                       ngroup = 3)

print(FLASSO_Train_CoxPH_Model_ExternalCalibration)

summary(FLASSO_Train_CoxPH_Model_ExternalCalibration)

plot(FLASSO_Train_CoxPH_Model_ExternalCalibration)

##################################
# Estimating survival curves
# of the FLASSO model
# for the risk groups
# using the test data
##################################
FLASSO_Test_CoxPH_Model_KMPlot <- kmplot( FLASSO_Train_CoxPH_Model_ExternalCalibration,
                                          group.name = c("High-Risk", "Medium-Risk", "Low-Risk"),
                                          time.at = 1:10 * 12)

##################################
# Conducting an external calibration
# of the FLASSO model
# using the test data
# for Year 10 (Time = 120)
##################################
FLASSO_Train_CoxPH_Model_ExternalCalibration <- calibrate_external(FLASSO_Train_CoxPH_Fit,
                                                       FLASSO_Train_Predictors,
                                                       FLASSO_Train_Time,
                                                       FLASSO_Train_Status,
                                                       FLASSO_Test_Predictors,
                                                       FLASSO_Test_Time,
                                                       FLASSO_Test_Status,
                                                       pred.at = 120,
                                                       ngroup = 3)

print(FLASSO_Train_CoxPH_Model_ExternalCalibration)

summary(FLASSO_Train_CoxPH_Model_ExternalCalibration)

plot(FLASSO_Train_CoxPH_Model_ExternalCalibration)

##################################
# Estimating survival curves
# of the FLASSO model
# for the risk groups
# using the test data
##################################
FLASSO_Test_CoxPH_Model_KMPlot <- kmplot( FLASSO_Train_CoxPH_Model_ExternalCalibration,
                                          group.name = c("High-Risk", "Medium-Risk", "Low-Risk"),
                                          time.at = 1:10 * 12)

```

</details>

##  1.6 Penalized Model Comparison Summary
|
| Model performance comparison:
|
| **[A]** All models had considerably high time-dependent AUROC overall although most reported lower values (and wider confidence intervals) at the 108th and 120th time periods potentially due to lesser case numbers for these survival times.
|
| **[B]** The method which demonstrated consistent time-dependent AUROC across all the time periods was **FLASSO: Fused Least Absolute Shrinkage and Selection Operator** (<mark style="background-color: #CCECFF">**survival**</mark>,<mark style="background-color: #CCECFF">**hdnom**</mark> and <mark style="background-color: #CCECFF">**penalized**</mark> packages) with the most optimal number of retained predictors at 3.
|
| **[C]** Lesser number of retained predictors were noted for the **LASSO: Least Absolute Shrinkage and Selection Operator** and **ENET: Elastic Net** (<mark style="background-color: #CCECFF">**survival**</mark>, <mark style="background-color: #CCECFF">**hdnom**</mark>, <mark style="background-color: #CCECFF">**penalized**</mark> and <mark style="background-color: #CCECFF">**glmnet**</mark> packages) methods with 5 and 7, respectively.
|
| **[D]** Time-dependent AUROC for the **MCP: Minimax Concave Penalty** and **SCAD: Smoothly Clipped Absolute Deviation** (<mark style="background-color: #CCECFF">**survival**</mark>, <mark style="background-color: #CCECFF">**hdnom**</mark>, <mark style="background-color: #CCECFF">**penalized**</mark> and <mark style="background-color: #CCECFF">**ncvreg**</mark> packages) methods were comparable all across the time periods with retained number of predictors equal to 13 and 15, respectively.
|
|

<details><summary><mark style="background-color: #000000;color: #FFFFFF">**Code Chunk | Output**</mark></summary>

```{r section_1.6, warning=FALSE, message=FALSE}
##################################
# Consolidating all results
##################################
(TDAUROC_Summary <- rbind(LASSO_Train_IV_Summary,
                         LASSO_Train_EV_Summary,
                         ENET_Train_IV_Summary,
                         ENET_Train_EV_Summary,
                         MCP_Train_IV_Summary,
                         MCP_Train_EV_Summary,
                         SCAD_Train_IV_Summary,
                         SCAD_Train_EV_Summary,
                         FLASSO_Train_IV_Summary,
                         FLASSO_Train_EV_Summary))

TDAUROC_Summary$Model <- factor(TDAUROC_Summary$Model,
                                levels = c("LASSO",
                                           "ENET",
                                           "MCP",
                                           "SCAD",
                                           "FLASSO"))

TDAUROC_Summary$Time  <- as.factor(TDAUROC_Summary$Time)
TDAUROC_Summary$Time  <- factor(TDAUROC_Summary$Time,
                                levels= c("12","24","36","48","60",
                                          "72","84","96","108","120"))

(TDAUROC_Plot <- dotplot(Model ~ MedianTDAUROC | Time,
                         data = TDAUROC_Summary,
                         groups = Validation,
                         main = "Penalized Model Performance Comparison",
                         ylab = "Model",
                         xlab = "Time-Dependent AUROC",
                         auto.key = list(adj = 1),
                         type=c("p", "h"),   
                         origin = 0,
                         alpha = 0.45,
                         pch = 16,
                         cex = 2,
                         layout = c(5,2)))
```

</details>


# **2. References**
|
| **[Book]** [Clinical Prediction Models](http://clinicalpredictionmodels.org/) by Ewout Steyerberg
| **[Book]** [Survival Analysis: A Self-Learning Text](https://link.springer.com/book/10.1007/978-1-4419-6646-9/) by David Kleinbaum and Mitchel Klein
| **[Book]** [Applied Survival Analysis Using R](https://link.springer.com/book/10.1007/978-3-319-31245-3/) by Dirk Moore
| **[Book]** [Regression Modeling Strategies](https://link.springer.com/book/10.1007/978-3-319-19425-7/) by Frank Harrell
| **[Book]** [R for Health Data Science](https://argoshare.is.ed.ac.uk/healthyr_book/) by Ewen Harrison and Riinu Pius
| **[Book]** [Supervised Machine Learning](https://bookdown.org/mpfoley1973/supervised-ml/) by Michael Foley
| **[Book]** [Data Science for Biological, Medical and Health Research](https://thomaselove.github.io/432-notes/index.html) by Thomas Love
| **[R Package]** [survival](https://cran.microsoft.com/snapshot/2022-04-01/web/packages/survival/index.html/) by Terry Therneau
| **[R Package]** [survminer](https://cran.r-project.org/web/packages/survminer/index.html/) by Alboukadel Kassambara
| **[R Package]** [mice](https://www.gerkovink.com/miceVignettes/) by Gerko Vink and Stef van Buuren
| **[R Package]** [foreign](https://cran.r-project.org/web/packages/foreign/index.html/) by R Core Team
| **[R Package]** [rms](https://cran.r-project.org/web/packages/rms/index.html/) by Frank Harrell
| **[R Package]** [Hmisc](https://cran.r-project.org/web/packages/Hmisc//) by Frank Harrell and Charles Dupont
| **[R Package]** [VIM](https://cran.r-project.org/web/packages/VIM/index.html/) by Matthias Templ
| **[R Package]** [gridExtra](https://cran.microsoft.com/snapshot/2017-08-01/web/packages/gridExtra/index.html/) by Baptiste Auguie
| **[R Package]** [finalfit](https://cran.r-project.org/web/packages/finalfit/index.html/) by Ewen Harrison
| **[R Package]** [knitr](https://cran.r-project.org/web/packages/knitr/index.html/) by Yihui Xie
| **[R Package]** [dplyr](https://cran.r-project.org/web/packages/dplyr/index.html/) by Hadley Wickham
| **[R Package]** [gtsummary](https://cran.r-project.org/web/packages/gtsummary/index.html/) by Daniel Sjoberg
| **[R Package]** [tidyr](https://cran.r-project.org/web/packages/tidyr/index.html/) by Hadley Wickham
| **[R Package]** [purrr](https://cran.r-project.org/web/packages/purrr//) by Lionel Henry
| **[R Package]** [moments](https://cran.r-project.org/web/packages/moments/index.html) by Lukasz Komsta and Frederick Novomestky
| **[R Package]** [skimr](https://cran.r-project.org/web/packages/skimr/skimr.pdf) by  Elin Waring
| **[R Package]** [caret](https://topepo.github.io/caret/index.html) by Max Kuhn
| **[R Package]** [corrplot](https://cran.r-project.org/web/packages/corrplot/corrplot.pdf) by Taiyun Wei
| **[R Package]** [SurvMetrics](https://cran.r-project.org/web/packages/SurvMetrics/SurvMetrics.pdf) by Hanpu Zhou
| **[R Package]** [randomForestSRC](https://cran.r-project.org/web/packages/randomForestSRC/randomForestSRC.pdf) by Hemant Ishwaran and Udaya Kogalur
| **[R Package]** [pec](https://cran.r-project.org/web/packages/pec/pec.pdf) by Thomas Gerds
| **[R Package]** [hdnom](https://cran.r-project.org/web/packages/hdnom/hdnom.pdf) by Nan Xiao
| **[R Package]** [ncvreg](https://cran.r-project.org/web/packages/ncvreg/ncvreg.pdf) by Patrick Breheny
| **[Article]** [An Introduction to hdnom](https://cran.r-project.org/web/packages/hdnom/vignettes/hdnom.html) by Nan Xiao
| **[Article]** [Penalized Cox Models](https://scikit-survival.readthedocs.io/en/stable/user_guide/coxnet.html) by Scikit Survival Team
| **[Article]** [Regularized Cox Regression](https://glmnet.stanford.edu/articles/Coxnet.html) by Kenneth Tay, Noah Simon, Jerome Friedman, Trevor Hastie, Rob Tibshirani and Balasubramanian Narasimhan
| **[Article]** [An Introduction to hdnom](https://cran.r-project.org/web/packages/hdnom/vignettes/hdnom.html) by Nan Xiao
| **[Article]** [An Introduction to hdnom](https://cran.r-project.org/web/packages/hdnom/vignettes/hdnom.html) by Nan Xiao
| **[Article]** [An Introduction to hdnom](https://cran.r-project.org/web/packages/hdnom/vignettes/hdnom.html) by Nan Xiao
| **[Article]** [Predictive Evaluation Metrics in Survival Analysis](https://cran.r-project.org/web/packages/SurvMetrics/vignettes/SurvMetrics-vignette.html) by Zhou Hanpu
| **[Article]** [Survival Analysis](https://sphweb.bumc.bu.edu/otlt/MPH-Modules/BS/BS704_Survival/index.html) by Lisa Sullivan
| **[Article]** [Survival Analysis in R](https://www.emilyzabor.com/tutorials/survival_analysis_in_r_tutorial.html) by Emily Zabor
| **[Article]** [Assessment of Discrimination in Survival Analysis](https://rstudio-pubs-static.s3.amazonaws.com/3506_36a9509e9d544386bd3e69de30bca608.html) by R-Studio Team
| **[Article]** [Cox Proportional-Hazards Regression](https://www.medcalc.org/manual/cox-regression.php) by MedCalc Team
| **[Article]** [Cox Proportional-Hazards Model](https://rstudio-pubs-static.s3.amazonaws.com/3506_36a9509e9d544386bd3e69de30bca608.html) by R Studio Team
| **[Article]** [Exploring Time To Event / Survival Data](https://thomaselove.github.io/432-notes/exploring-time-to-event-survival-data.html) by Thomas Love
| **[Article]** [Survival Analysis](http://www.sthda.com/english/wiki/survival-analysis) by Alboukadel Kassambara
| **[Article]** [Survival Analysis with R](https://rviews.rstudio.com/2017/09/25/survival-analysis-with-r/) by Joseph Rickert
| **[Article]** [Cox Model Assumptions](http://www.sthda.com/english/wiki/cox-model-assumptions#testing-non-linearity) by Alboukadel Kassambara
| **[Article]** [Understanding Predictions in Survival Analysis](https://scikit-survival.readthedocs.io/en/stable/user_guide/understanding_predictions.html) by Scikit Team
| **[Article]** [Regularization in R Tutorial: Ridge, Lasso and Elastic Net](https://www.datacamp.com/tutorial/tutorial-ridge-lasso-elastic-net) by Datacamp Team
| **[Article]** [Penalized Regression Essentials: Ridge, Lasso & Elastic Net](http://sthda.com/english/articles/37-model-selection-essentials-in-r/153-penalized-regression-essentials-ridge-lasso-elastic-net) by STHDA Team
| **[Article]** [Lasso vs Ridge vs Elastic Net | ML](https://www.geeksforgeeks.org/lasso-vs-ridge-vs-elastic-net-ml/) by Geeks for Geeks Team
| **[Article]** [Lasso Regression Explained, Step by Step](https://machinelearningcompass.com/machine_learning_models/lasso_regression/) by Boris Giba
| **[Article]** [How to Develop LASSO Regression Models in Python](https://machinelearningmastery.com/lasso-regression-with-python/) by Jason Brownlee
| **[Article]** [Introduction to Lasso Regression](https://www.statology.org/lasso-regression/) by Statology Team
| **[Article]** [Elastic Net Regression Explained, Step by Step](https://machinelearningcompass.com/machine_learning_models/elastic_net_regression/) by Boris Giba
| **[Article]** [How to Develop Elastic Net Regression Models in Python](https://machinelearningmastery.com/elastic-net-regression-in-python/) by Jason Brownlee
| **[Article]** [Adaptive Lasso: What It Is and How to Implement in R](https://ricardocarvalho.ca/post/lasso/) by Ricardo Carvalho
| **[Article]** [L1 Penalization: The Lasso and Adaptive Lasso](http://www.personal.psu.edu/lxx6/Lasso.pdf) by Justin Petrovich
| **[Article]** [Adaptive Lasso, MCP, and SCAD](https://myweb.uiowa.edu/pbreheny/7600/s16/notes/2-29.pdf) by Patrick Breheny
| **[Article]** [The Smoothly Clipped Absolute Deviation (SCAD) penalty](https://andrewcharlesjones.github.io/journal/scad.html) by Andrew Jones
| **[Article]** [Fused Lasso](https://myweb.uiowa.edu/pbreheny/7240/s19/notes/5-01.pdf) by Patrick Breheny
| **[Publication]** [Survival Analysis Part I: Basic Concepts and First Analyses](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2394262/) by Taane Clark (British Journal of Cancer)
| **[Publication]** [Survival Analysis Part II: Multivariate Data Analysis  An Introduction to Concepts and Methods](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2394368/) by Mike Bradburn (British Journal of Cancer)
| **[Publication]** [Survival Analysis Part III: Multivariate Data Analysis  Choosing a Model and Assessing its Adequacy and Fit](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2376927/) by Mike Bradburn (British Journal of Cancer)
| **[Publication]** [Survival Analysis Part IV: Further Concepts and Methods in Survival Analysis](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2394469/) by Taane Clark (British Journal of Cancer)
| **[Publication]** [Regression Models and Life-Tables](https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1972.tb00899.x) by David Cox (Royal Statistical Society)
| **[Publication]** [Regression Shrinkage and Selection Via the Lasso](https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1996.tb02080.x) by Rob Tibshirani (Journal of the Royal Statistical Society)
| **[Publication]** [The Adaptive Lasso and Its Oracle Properties](https://www.tandfonline.com/doi/pdf/10.1198/016214506000000735) by Hui Zou (Journal of the American Statistical Association)
| **[Publication]** [Regularization and Variable Selection via the Elastic Net](https://rss.onlinelibrary.wiley.com/doi/10.1111/j.1467-9868.2005.00503.x) by Hui Zou and Trevor Hastie (Journal of the Royal Statistical Society)
| **[Publication]** [On The Adaptive Elastic-Net With a Diverging Number of Parameters](https://pubmed.ncbi.nlm.nih.gov/20445770/) by Hui Zou and Hao Helen Zhang (Annals of Statistics)
| **[Publication]** [Adaptive Elastic Net Method for Cox Model](https://arxiv.org/abs/1507.06371) by Chunhong Li, Xinxing Wei and Hongshuai Dai (arXiv e-prints)
| **[Publication]** [Coordinate Descent Algorithms for Non-Convex Penalized Regression with Applications to Biological Feature Selection](https://pubmed.ncbi.nlm.nih.gov/22081779/) by Patrick Breheny and Jian Huang (The Annals of Applied Statistics)
| **[Publication]** [Regularization Paths for Cox's Proportional Hazards Model via Coordinate Descent](https://pubmed.ncbi.nlm.nih.gov/27065756/) by Noah Simon, Jerome Friedman, Trevor Hastie and Rob Tibshirani (Journal of Statistical Software)
| **[Publication]** [Nearly Unbiased Variable Selection Under Minimax Concave Penalty](https://www.jstor.org/stable/25662264) by Cunhui Zhang (The Annals of Statistics)
| **[Publication]** [Variable Selection via Nonconcave Penalized Likelihood and its Oracle Properties](https://www.tandfonline.com/doi/abs/10.1198/016214501753382273) by Jianqing Fan and Runze Li (Journal of the American Statistical Association )
| **[Publication]** [Sparsity and Smoothness via the Fused Lasso](https://www.jstor.org/stable/3647602) by Robert Tibshirani, Michael Saunders, Saharon Rosset, Ji Zhu and Keith Knight (Journal of the Royal Statistical Society)
| **[Tutorial]** [Survival Analysis / Time-To-Event Analysis in R](https://campus.datacamp.com/courses/survival-analysis-in-r/what-is-survival-analysis?ex=1) by Heidi Seibold (Datacamp)
|
|
|
|
